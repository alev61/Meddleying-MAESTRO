{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Meddleying MAESTRO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Meddleying-MAESTRO/blob/main/Meddleying_MAESTRO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA0W-VK1JVQl"
      },
      "source": [
        "# Meddleying MAESTRO (ver 2.6)\n",
        "\n",
        "***\n",
        "\n",
        "## A full-featured Algorithmic Intelligence music generator with full multi-instrument MIDI support.\n",
        "\n",
        "***\n",
        "\n",
        "### Project Los Angeles\n",
        "\n",
        "### Tegridy Code 2020\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eftzIVKrqR5S"
      },
      "source": [
        "# Setup Environment, clone needed code, and install all required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsUtsJGNz6f2",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "!pip install pretty_midi\n",
        "!pip install visual_midi\n",
        "\n",
        "!curl -L \"https://raw.githubusercontent.com/asigalov61/Meddleying-MAESTRO/main/MIDI.py\" > 'MIDI.py'\n",
        "\n",
        "!mkdir '/content/Dataset/'\n",
        "!mkdir '/content/C_Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8B3p6QySmE",
        "cellView": "form"
      },
      "source": [
        "#@title Import all modules\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import music21\n",
        "from music21 import *\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "import tqdm.auto\n",
        "import secrets\n",
        "import pretty_midi\n",
        "from google.colab import output, drive\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from mido import MidiFile\n",
        "from IPython.display import display, Image\n",
        "import MIDI\n",
        "from visual_midi import Plotter\n",
        "from visual_midi import Preset\n",
        "from pretty_midi import PrettyMIDI\n",
        "ticks_per_note = 50\n",
        "ctime = 0\n",
        "cev_matrix = []\n",
        "cnotes_matrix = []\n",
        "debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Pv5eNRqiyr"
      },
      "source": [
        "# Select and download a sample MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bFuzEwrshWCk"
      },
      "source": [
        "#@title (Best Choice/Multi-Instrumental) Processed ready-to-use Special Tegridy Multi-Instrumental Dataset\n",
        "%cd /content/\n",
        "!wget 'https://github.com/asigalov61/Meddleying-MAESTRO/raw/main/Meddleying-MAESTRO-Music-Dataset.data'\n",
        "#!unzip -j Meddleying-MAESTRO-Music-Dataset.data\n",
        "#!rm Meddleying-MAESTRO-Music-Dataset.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh0fYeVMITLY",
        "cellView": "form"
      },
      "source": [
        "#@title (BEST Choice / Multi-Intrumental) Special Tegridy MIDI Multi-Instrumental Dataset (~325 MIDIs) \n",
        "%cd /content/Dataset/\n",
        "!wget 'https://github.com/asigalov61/Meddleying-MAESTRO/raw/main/Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!unzip -j 'Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!rm 'Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhf6GtCGIbJU",
        "cellView": "form"
      },
      "source": [
        "#@title (Piano Performance Dataset) Download Google Magenta MAESTRO v.2.0.0 Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Dataset/\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip\n",
        "!rm maestro-v2.0.0-midi.zip\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4oa9lUWLPN5",
        "cellView": "form"
      },
      "source": [
        "#@title A simple code to unzip MIDI datasets without any hastle\n",
        "!mkdir /content/Dataset/\n",
        "%cd /content/Dataset/\n",
        "!unzip -j /content/Dataset/*.zip\n",
        "!rm /content/Dataset/*.zip\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jsEXxkDLQ9Z"
      },
      "source": [
        "# Process MIDI Dataset to MIDI Notes and MIDI Events Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYHrPooT8Oq2",
        "cellView": "form"
      },
      "source": [
        "#@title Please note that transpose function reduces MIDIs to Piano only. Sliding some sliders to minimum value disables slider's option. Standard MIDI timings are 400/120\n",
        "full_path_to_output_dataset_to = \"/content/Meddleying-MAESTRO-Music-Dataset.data\" #@param {type:\"string\"}\n",
        "dataset_slices_length_in_notes = 2 #@param {type:\"slider\", min:2, max:60, step:1}\n",
        "transpose_MIDIs_to_one_key = False #@param {type:\"boolean\"}\n",
        "melody_reduction_to_slices_max_pitches = False #@param {type:\"boolean\"}\n",
        "desired_MIDI_channel = 16 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "flip_input_dataset = False #@param {type:\"boolean\"}\n",
        "remove_drums = False #@param {type:\"boolean\"}\n",
        "flip_notes = False #@param {type:\"boolean\"}\n",
        "transpose_notes_pitch = 0 #@param {type:\"slider\", min:-30, max:30, step:1}\n",
        "remove_random_notes = False #@param {type:\"boolean\"}\n",
        "remove_every_randomth_note = False #@param {type:\"boolean\"}\n",
        "remove_every_n_notes = False #@param {type:\"boolean\"}\n",
        "remove_n_notes_per_slice = 0 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "remove_every_nth_note = 0 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "keep_only_notes_above_this_pitch_number = 0 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "constant_notes_duration_time_ms = 0 #@param {type:\"slider\", min:0, max:800, step:100}\n",
        "five_notes_per_octave_pitch_quantization = False #@param {type:\"boolean\"}\n",
        "octave_channel_split = False #@param {type:\"boolean\"}\n",
        "simulated_velocity_volume = 2 #@param {type:\"slider\", min:2, max:127, step:1}\n",
        "simulated_velocity_range = 1 #@param {type:\"slider\", min:1, max:127, step:1}\n",
        "simulated_velocity_multiplier = 1.2 #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "simulated_velocity_based_on_pitch = False #@param {type:\"boolean\"}\n",
        "simulated_velocity_based_on_top_pitch = True #@param {type:\"boolean\"}\n",
        "simulated_velocity_top_pitch_shift_pitch = 1 #@param {type:\"slider\", min:1, max:120, step:1}\n",
        "simulated_velocity_baseline_pitch = 1 #@param {type:\"slider\", min:1, max:127, step:1}\n",
        "simulated_velocity_chord_size_in_notes = 0 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "reverse_output_dataset = True #@param {type:\"boolean\"}\n",
        "combine_reversed_and_original_datasets_together = True #@param {type:\"boolean\"}\n",
        "debug = False\n",
        "\n",
        "os.chdir(\"/content/\")\n",
        "\n",
        "ev_matrix = []\n",
        "rev_matrix = []\n",
        "not_matrix = []\n",
        "rnot_matrix = []\n",
        "durations_matrix = []\n",
        "velocities_matrix = []\n",
        "files_count = 0\n",
        "remnote = 0\n",
        "remnote_count = 0\n",
        "notes_counter = 0\n",
        "every_random_note = 7\n",
        "itrack = 0\n",
        "prev_event = []\n",
        "next_event = []\n",
        "slice_events = []\n",
        "slices_pitches = []\n",
        "slices_events = []\n",
        "slices_melody_events = []\n",
        "slices_melody_pitches = []\n",
        "slices_counter = 0\n",
        "slices_count = 0\n",
        "chord_counter = 0\n",
        "max_event_pitch = 0\n",
        "\n",
        "def list_average(num):\n",
        "  sum_num = 0\n",
        "  for t in num:\n",
        "      sum_num = sum_num + t           \n",
        "\n",
        "  avg = sum_num / len(num)\n",
        "  return avg\n",
        "\n",
        "#converts all midi files in the current folder\n",
        "#converting everything into the key of C major or A minor\n",
        "# major conversions\n",
        "\n",
        "if transpose_MIDIs_to_one_key:\n",
        "\n",
        "  majors = dict([(\"A-\", 4),(\"A\", 3),(\"B-\", 2),(\"B\", 1),(\"C\", 0),(\"D-\", -1),(\"D\", -2),(\"E-\", -3),(\"E\", -4),(\"F\", -5),(\"G-\", 6),(\"G\", 5)])\n",
        "  minors = dict([(\"A-\", 1),(\"A\", 0),(\"B-\", -1),(\"B\", -2),(\"C\", -3),(\"D-\", -4),(\"D\", -5),(\"E-\", 6),(\"E\", 5),(\"F\", 4),(\"G-\", 3),(\"G\", 2)])\n",
        "\n",
        "\n",
        "  os.chdir(\"/content/Dataset/\")\n",
        "\n",
        "  print('Converting all possible MIDI files to C Key.')\n",
        "  print('This may take a while. Please wait...')\n",
        "\n",
        "  for file in tqdm.auto.tqdm(glob.glob(\"*.mid\")):\n",
        "    try:\n",
        "      score = music21.converter.parse(file)\n",
        "      key = score.analyze('key')\n",
        "\n",
        "      #print('Detected Key:', key.tonic.name, key.mode)\n",
        "\n",
        "      if key.mode == \"major\":\n",
        "            halfSteps = majors[key.tonic.name]\n",
        "            \n",
        "      elif key.mode == \"minor\":\n",
        "            halfSteps = minors[key.tonic.name]\n",
        "\n",
        "      newscore = score.transpose(halfSteps)\n",
        "      key = newscore.analyze('key')\n",
        "      #print('Detected Key:', key.tonic.name, key.mode)\n",
        "      newFileName = \"/content/C_Dataset/C_\" + file\n",
        "      newscore.write('midi',newFileName)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "os.chdir(\"/content/\")\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "if not transpose_MIDIs_to_one_key :\n",
        "  dataset_addr = \"Dataset\"\n",
        "else:\n",
        "  dataset_addr = \"C_Dataset\"\n",
        "files = os.listdir(dataset_addr)\n",
        "print('Now processing the files.')\n",
        "print('Please stand-by...')\n",
        "\n",
        "for file in tqdm.auto.tqdm(files):\n",
        "    file_address = os.path.join(dataset_addr, file)\n",
        "    \n",
        "    score = []\n",
        "\n",
        "    midi_file = open(file_address, 'rb')\n",
        "    if debug: print('Processing File:', file_address)\n",
        "\n",
        "    score2 = MIDI.midi2opus(midi_file.read())\n",
        "    score1 = MIDI.to_millisecs(score2)\n",
        "    score3 = MIDI.opus2score(score1)\n",
        "    score = score3\n",
        "    midi_file.close()\n",
        "\n",
        "    if remove_drums:\n",
        "      score4 = MIDI.grep(score3, [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15])\n",
        "    else:\n",
        "      score4 = score3\n",
        "  \n",
        "    if desired_MIDI_channel < 16:\n",
        "      score = MIDI.grep(score4, [desired_MIDI_channel-1])\n",
        "    else:\n",
        "      score = score4\n",
        "    \n",
        "    itrack = 1\n",
        "    while itrack < len(score):\n",
        "      for event in score[itrack]:\n",
        "        if event[0] == 'note':\n",
        "          if flip_input_dataset:\n",
        "            event[4] = 127 - event[4]\n",
        "\n",
        "          if five_notes_per_octave_pitch_quantization:\n",
        "            event[4] = int(math.floor(event[4] / 12 * 5) * 12 / 5)\n",
        "          \n",
        "          if octave_channel_split:\n",
        "            event[4] = int((event[4] + (event[3] - 4) * 12) % (127 - 12 * 2))\n",
        "          \n",
        "          if simulated_velocity_volume > 2 and simulated_velocity_range > 1:\n",
        "            event[5] = simulated_velocity_volume + int(secrets.randbelow(simulated_velocity_range) * simulated_velocity_multiplier)\n",
        "          \n",
        "          if simulated_velocity_based_on_pitch:\n",
        "            if event[4] >= simulated_velocity_baseline_pitch:\n",
        "              event[5] = int(simulated_velocity_volume * simulated_velocity_multiplier)\n",
        "            else:\n",
        "              if event[5] < simulated_velocity_baseline_pitch:\n",
        "                event[5] = int(simulated_velocity_baseline_pitch * simulated_velocity_multiplier)\n",
        "\n",
        "          if chord_counter < simulated_velocity_chord_size_in_notes:\n",
        "            event[5] = int(simulated_velocity_volume * simulated_velocity_multiplier)\n",
        "            chord_counter += 1\n",
        "          else:\n",
        "            chord_counter = 0\n",
        "            simulated_velocity_volume = int(event[4] * simulated_velocity_multiplier)\n",
        "          \n",
        "          if simulated_velocity_based_on_top_pitch:\n",
        "            if event[5] < simulated_velocity_baseline_pitch: \n",
        "              event[5] = int((max_event_pitch + simulated_velocity_top_pitch_shift_pitch) * simulated_velocity_multiplier)\n",
        "            else:\n",
        "              event[5] = max_event_pitch + simulated_velocity_top_pitch_shift_pitch\n",
        "          \n",
        "          if constant_notes_duration_time_ms > 0:\n",
        "            event[2] = constant_notes_duration_time_ms\n",
        "          \n",
        "          if transpose_notes_pitch:\n",
        "            event[4] = event[4] + transpose_notes_pitch\n",
        "          \n",
        "          if flip_notes:\n",
        "            event[4] = 127 - event[4]\n",
        "\n",
        "          if slices_counter != dataset_slices_length_in_notes:\n",
        "            slices_counter += 1\n",
        "            #remnote_count += 1\n",
        "            slices_events.append(event)\n",
        "            slices_pitches.append(event[4])\n",
        " \n",
        "          else:\n",
        "            slices_count += 1\n",
        "            slices_counter = 0\n",
        "            max_event_pitch = max(slices_pitches)\n",
        "            max_event_index = slices_pitches.index(max_event_pitch)\n",
        "            max_event = slices_events[max_event_index]\n",
        "            slices_melody_events.append(max_event)\n",
        "            slices_melody_pitches.append(max_event[4])\n",
        "            slices_events = []\n",
        "            slices_pitches = []\n",
        " \n",
        "          if remove_random_notes:\n",
        "            if secrets.randbelow(2) == 1:\n",
        "              remnote_count += 1\n",
        "            else:\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)\n",
        "\n",
        "          if keep_only_notes_above_this_pitch_number > 0:\n",
        "            if event[4] < keep_only_notes_above_this_pitch_number:\n",
        "              remnote_count += 1\n",
        "            else: \n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event) \n",
        "              slices_events.append(event)\n",
        "              slices_pitches.append(event[4])\n",
        "\n",
        "          if remove_every_n_notes > 0:\n",
        "            if remnote < remove_every_n_notes:\n",
        "              remnote += 1\n",
        "              remnote_count += 1\n",
        "            else:\n",
        "              remnote = 0\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)\n",
        "              slices_events.append(event)\n",
        "              slices_pitches.append(event[4])\n",
        "\n",
        "          if remove_n_notes_per_slice > 0:\n",
        "            if slices_counter == remove_n_notes_per_slice:\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)\n",
        "              slices_events.append(event)\n",
        "              slices_pitches.append(event[4])\n",
        "\n",
        "            else:\n",
        "              remnote_count += 1\n",
        "\n",
        "          if remove_every_nth_note > 0:\n",
        "            if remnote == remove_every_nth_note + 1:\n",
        "              remnote = 0 \n",
        "              remnote_count += 1\n",
        "            else:\n",
        "              remnote += 1\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)\n",
        "              slices_events.append(event)\n",
        "              slices_pitches.append(event[4])\n",
        "\n",
        "          if remove_every_randomth_note:\n",
        "            if remnote == every_random_note + 1:\n",
        "              remnote = 0\n",
        "              remnote_count += 1\n",
        "              every_random_note = secrets.randbelow(every_random_note+2)\n",
        "            else:\n",
        "              remnote += 1\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)\n",
        "              slices_events.append(event)\n",
        "              slices_pitches.append(event[4])\n",
        "          else:\n",
        "            not_matrix.append(event[4])\n",
        "            ev_matrix.append(event)\n",
        "            slices_events.append(event)\n",
        "            slices_pitches.append(event[4])\n",
        "            notes_counter += 1\n",
        "\n",
        "\n",
        "      itrack += 1\n",
        "\n",
        "  \n",
        "    # Calculate stats about the resulting dataset\n",
        "    average_note_pitch = 0\n",
        "    min_note = 0\n",
        "    max_note = 0\n",
        "    itrack = 1\n",
        "\n",
        "    while itrack < len(score):\n",
        "        for event in score[itrack]:\n",
        "          if event[0] == 'note':\n",
        "            min_note = int(min(min_note, event[4]))\n",
        "            max_note = int(max(min_note, event[4]))\n",
        "        itrack += 1\n",
        "\n",
        "    files_count += 1\n",
        "    if debug:\n",
        "      print('File:', midi_file)\n",
        "\n",
        "if melody_reduction_to_slices_max_pitches:\n",
        "  not_matrix = slices_melody_pitches\n",
        "  ev_matrix = slices_melody_events\n",
        "\n",
        "if reverse_output_dataset:\n",
        "  print('Augmenting the dataset now to reduce plagiarizm and repetitions.')\n",
        "  rnot_matrix = not_matrix\n",
        "  rev_matrix = ev_matrix\n",
        "  rnot_matrix.reverse()\n",
        "  rev_matrix.reverse()\n",
        "  not_matrix = rnot_matrix\n",
        "  ev_matrix = rev_matrix\n",
        "if combine_reversed_and_original_datasets_together:\n",
        "  not_matrix += rnot_matrix\n",
        "  ev_matrix += rev_matrix\n",
        "  \n",
        "average_note_pitch = int(list_average(not_matrix))\n",
        "\n",
        "print('Task complete :)')\n",
        "print('==================================================')\n",
        "print('Number of processed dataset MIDI files:', files_count)\n",
        "if reverse_output_dataset: print('The dataset was augmented to prevent plagiarism as requested.')\n",
        "print('Number of notes in the dataset MIDI files:', notes_counter)\n",
        "if remnote_count > 0: print('Number of notes removed:', remnote_count)\n",
        "print('Number of notes in the resulting dataset:', len(not_matrix))\n",
        "if slices_count > 0: print('There are', slices_count, 'slices, each', dataset_slices_length_in_notes, 'notes long.')\n",
        "#print('Minimum note pitch:', min_note)\n",
        "#print('Maximum note pitch:', max_note)\n",
        "print('Number of total MIDI events recorded:', len(ev_matrix))\n",
        "print('Average note pitch:', average_note_pitch)\n",
        "print('First 5 notes of the resulting dataset:', ev_matrix[0:6])\n",
        "if remove_drums: print('Drums MIDI events have been removed as requested.')\n",
        "# define a list of places\n",
        "MusicDataset = [not_matrix, ev_matrix]\n",
        "\n",
        "with open(full_path_to_output_dataset_to, 'wb') as filehandle:\n",
        "    # store the data as binary data stream\n",
        "    pickle.dump(MusicDataset, filehandle)\n",
        "print('Dataset was saved at:', full_path_to_output_dataset_to)\n",
        "print('Task complete. Enjoy! :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TUUCQTxWp9U"
      },
      "source": [
        "# Load/Re-load the processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv4cUwf8yxJK",
        "cellView": "form"
      },
      "source": [
        "#@title Load pre-processed dataset from a file to memory\n",
        "full_path_to_dataset_file = \"/content/Meddleying-MAESTRO-Music-Dataset.data\" #@param {type:\"string\"}\n",
        "\n",
        "not_matrix = []\n",
        "ev_matrix = []\n",
        "\n",
        "with open(full_path_to_dataset_file, 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    MusicDataset = pickle.load(filehandle)\n",
        "    not_matrix = MusicDataset[0]\n",
        "    ev_matrix = MusicDataset[1]\n",
        "    events_matrix = ev_matrix\n",
        "    notes_matrix = not_matrix\n",
        "\n",
        "print('Task complete. Enjoy! :)')\n",
        "print('==================================================')\n",
        "print('Number of notes in the dataset:', len(not_matrix))\n",
        "print('Number of total MIDI events recorded:', len(ev_matrix))\n",
        "print('Done! Enjoy! :)')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJyApDLFNOwb"
      },
      "source": [
        "# Custom MIDI / priming sequence option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlJ0itWgyA6E",
        "cellView": "form"
      },
      "source": [
        "#@title PRO Tip: Try to match at least an end_note duration and/or velocity for best results\n",
        "full_path_to_MIDI_file = \"/content/seed3.mid\" #@param {type:\"string\"}\n",
        "MIDI_channels_selection = \"all\" #@param [\"all\"] {allow-input: true}\n",
        "start_note_index = 0 #@param {type:\"number\"}\n",
        "end_note_index =  120#@param {type:\"number\"}\n",
        "score = []\n",
        "cev_matrix = []\n",
        "cnotes_matrix = []\n",
        "ctime = 0\n",
        "ctime = 0\n",
        "midi_file = open(full_path_to_MIDI_file, 'rb')\n",
        "if debug: print('Processing File:', file_address)\n",
        "\n",
        "if MIDI_channels_selection == 'all':\n",
        "  score1 = MIDI.midi2score(midi_file.read())\n",
        "else:\n",
        "  score0 = MIDI.midi2score(midi_file.read())\n",
        "  score1 = MIDI.grep(score0, [int(MIDI_channels_selection)])\n",
        "midi_file.close()\n",
        "score2 = MIDI.score2opus(score1)\n",
        "score3 = MIDI.to_millisecs(score2)\n",
        "score = MIDI.opus2score(score3)\n",
        "cnotes_matrix = []\n",
        "cev_matrix = []\n",
        "x = 0\n",
        "itrack = 1\n",
        "while itrack < len(score):\n",
        "    for event in score[itrack]:\n",
        "       if event[0] == 'note':\n",
        "          if x >= start_note_index and x <= end_note_index: \n",
        "            cnotes_matrix.append(event[4])\n",
        "          if x >= start_note_index and x <= end_note_index:    \n",
        "            cev_matrix.append(['note', ctime, event[2], event[3], event[4], event[5]])\n",
        "            #ctime += ticks_per_note\n",
        "            ctime = event[1]\n",
        "          x += 1\n",
        "    itrack += 1\n",
        "  \n",
        "if debug:\n",
        "  print('File:', midi_file)\n",
        "print('Results:')\n",
        "events_matrix = ev_matrix\n",
        "start_event = cev_matrix[-1]\n",
        "\n",
        "cindex = 0\n",
        "index2 = 0\n",
        "index4 = 0\n",
        "index3 = 0\n",
        "index5 = 0\n",
        "\n",
        "for i in range(len(events_matrix)):\n",
        "  if events_matrix[i][4] == start_event[4]:\n",
        "    index4 = i\n",
        "    if debug: print('Found matching continuation primer note.')\n",
        "    if events_matrix[i][5] == start_event[5]:\n",
        "      index2 = i\n",
        "      if debug: print('Found matching continuation primer velocity.')\n",
        "      if events_matrix[i][2] == start_event[2]:\n",
        "        index5 = i\n",
        "        if debug: print('Found matching continuation duration.')\n",
        "        if events_matrix[i][3] == start_event[3]:\n",
        "          index3 = i\n",
        "          if debug: print('Found matching continuation MIDI channel.')\n",
        "          if debug: print('Found matching continuation MIDI event.')\n",
        "cindex = 0\n",
        "\n",
        "if index4 != 0: cindex = index4, print('Found a matching note.')\n",
        "if index5 != 0: cindex = index5, print('Found a matching velocity.')\n",
        "if index2 != 0: cindex = index2, print('Found a matching duration.')\n",
        "if index3 != 0: cindex = index3, print('Found a matching MIDI channel.')\n",
        "cindex = int(cindex[0])\n",
        "if cindex != 0:\n",
        "  print('Success. Continuation is possible. Enjoy! :)')\n",
        "  print('Number of notes in the primer composition:', len(cnotes_matrix))\n",
        "  print('Found matching Dataset index #:', cindex)\n",
        "  print('Primer MIDI last event/continuation event:', start_event)\n",
        "else:\n",
        "  print('Sorry, but there are no matching MIDI events in the dataset to continue given primer composition.')\n",
        "  print('Try to use a different End Note value (end_note_index), a larger dataset, a different primer compostion')\n",
        "  print('Or you can try different dataset/primer processing settings. You can also try including your primer into the dataset.')\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_vNoEXeNeya"
      },
      "source": [
        "# Generate Music\n",
        "\n",
        "Standard MIDI timings are 400/120(80).\n",
        "Recommended settings are: notes per slice = 30 and notes timings multiplier range is 0.95 <> 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_NcxuTHu2Ho",
        "cellView": "form"
      },
      "source": [
        "#@title Play with the settings until you get what you like \n",
        "attention_span = \"augmentation1\" #@param [\"augmentation1\", \"augmentation2\"]\n",
        "start_note = 30 #@param {type:\"slider\", min:1, max:127, step:1}\n",
        "notes_per_slice = 60 #@param {type:\"slider\", min:5, max:60, step:1}\n",
        "number_of_slices = 150 #@param {type:\"slider\", min:5, max:400, step:5}\n",
        "relative_note_timings = False\n",
        "relative_note_timings = True #@param {type:\"boolean\"}\n",
        "output_ticks = 400 #@param {type:\"slider\", min:0, max:2000, step:100}\n",
        "ticks_per_note = 180 #@param {type:\"slider\", min:0, max:2000, step:10}\n",
        "ticks_durations_multiplier = 1\n",
        "notes_timings_multiplier = 0.97 #@param {type:\"slider\", min:0, max:2, step:0.01}\n",
        "notes_durations_multiplier = 1.25 #@param {type:\"slider\", min:0.5, max:1.5, step:0.01}\n",
        "notes_velocities_multiplier = 1.5 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "transpose_velocity = -30 #@param {type:\"slider\", min:-60, max:60, step:1}\n",
        "transpose_composition = 0 #@param {type:\"slider\", min:-30, max:30, step:1}\n",
        "set_all_MIDI_patches_to_piano = True #@param {type:\"boolean\"}\n",
        "MIDI_channel_patch_00 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_01 = 24 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_02 = 32 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_03 = 40 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_04 = 42 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_05 = 46 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_06 = 56 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_07 = 71 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_08 = 73 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_09 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_10 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_11 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_12 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_13 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_14 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_15 = 0 #@param {type:\"number\"}\n",
        "\n",
        "#===TODO===\n",
        "melody_only_output_for_melody_datasets = False\n",
        "#===\n",
        "output_events_matrix = []\n",
        "output_events_matrix1 = []\n",
        "midi_data = []\n",
        "midi_dats1 = []\n",
        "events_matrix = []\n",
        "notes_matrix = []\n",
        "index = 0\n",
        "index1 = 0\n",
        "time = 0\n",
        "x = 0\n",
        "output = []\n",
        "output1 = []\n",
        "average_note_pitch = 100\n",
        "time_r = 0\n",
        "ovent = []\n",
        "ovent_r = []\n",
        "ovent_a = []\n",
        "start_event = []\n",
        "event4 = []\n",
        "event3 = []\n",
        "event2 = []\n",
        "event1 = [] \n",
        "event = []\n",
        "event01 = [] \n",
        "event02 = []\n",
        "event03 = [] \n",
        "event04 = []\n",
        "global_time = []\n",
        "\n",
        "if set_all_MIDI_patches_to_piano:\n",
        "  output = [output_ticks, [['track_name', 0, b'Meddleying MAESTRO']]]\n",
        "else:\n",
        "  output = [output_ticks,\n",
        "            [['track_name', 0, b'Meddleying MAESTRO'], \n",
        "              ['patch_change', 0, 0, MIDI_channel_patch_00], \n",
        "              ['patch_change', 0, 1, MIDI_channel_patch_01],\n",
        "              ['patch_change', 0, 2, MIDI_channel_patch_02],\n",
        "              ['patch_change', 0, 3, MIDI_channel_patch_03],\n",
        "              ['patch_change', 0, 4, MIDI_channel_patch_04],\n",
        "              ['patch_change', 0, 5, MIDI_channel_patch_05],\n",
        "              ['patch_change', 0, 6, MIDI_channel_patch_06],\n",
        "              ['patch_change', 0, 7, MIDI_channel_patch_07],\n",
        "              ['patch_change', 0, 8, MIDI_channel_patch_08],\n",
        "              ['patch_change', 0, 9, MIDI_channel_patch_09],\n",
        "              ['patch_change', 0, 10, MIDI_channel_patch_10],\n",
        "              ['patch_change', 0, 11, MIDI_channel_patch_11],\n",
        "              ['patch_change', 0, 12, MIDI_channel_patch_12],\n",
        "              ['patch_change', 0, 13, MIDI_channel_patch_13],\n",
        "              ['patch_change', 0, 14, MIDI_channel_patch_14],\n",
        "              ['patch_change', 0, 15, MIDI_channel_patch_15],]]\n",
        "output1 = output\n",
        "output_events_matrix = [['track_name', 0, b'Composition Track']]\n",
        "output_events_matrix1 = [['track_name', 0, b'Composition Track']]        \n",
        "\n",
        "#output.append(output_events_matrix)    \n",
        "#output1.append(output_events_matrix1)\n",
        "\n",
        "if ctime > 0:\n",
        "  time = ctime\n",
        "else:\n",
        "  time = 0\n",
        "\n",
        "if melody_only_output_for_melody_datasets:\n",
        "  try:\n",
        "    index1 = slices_melody_pitches.index(start_note)\n",
        "    index = index1+augmentation_strength*2\n",
        "  except:\n",
        "    index1 = slices_melody_pitches.index(average_note_pitch)\n",
        "    index = index1+augmentation_strength*2\n",
        "\n",
        "try:\n",
        "  if len(cev_matrix) != 0:\n",
        "    events_matrix = ev_matrix\n",
        "    notes_matrix = not_matrix\n",
        "    output_events_matrix = cev_matrix\n",
        "    start_note = cnotes_matrix[-1]\n",
        "    index = cindex\n",
        "    print('Priming_sequence: MIDI event:', cev_matrix[-1])\n",
        "    cev_matrix = 0\n",
        "    ctime = 0\n",
        "  else:\n",
        "    events_matrix = ev_matrix\n",
        "    notes_matrix = not_matrix\n",
        "    index = not_matrix.index(start_note, secrets.choice(range(len(not_matrix))))\n",
        "    print('Priming_sequence: MIDI note #', [start_note])\n",
        "\n",
        "except: \n",
        "  print('The Generator could not find the starting note in a dataset note sequence. Please adjust the parameters.')\n",
        "  print('Meanwhile, trying to generate a sequence with the MIDI note # [60]')\n",
        "  \n",
        "  try:\n",
        "    index = not_matrix.index(60, secrets.choice(range(len(not_matrix))))\n",
        "\n",
        "  except:\n",
        "    print('Unfortunatelly, that did not work either. Please try again/restart run-time.')\n",
        "    sys.exit()\n",
        "\n",
        "for i in tqdm.auto.tqdm(range(number_of_slices)):\n",
        "  for k in range(notes_per_slice):\n",
        "    if attention_span == 'augmentation1' or 'augmentation2':\n",
        "      if k > 3:\n",
        "        try:\n",
        "          event03 = events_matrix[index+k-4]\n",
        "          event02 = events_matrix[index+k-3]\n",
        "          event01 = events_matrix[index+k-2]\n",
        "          event0 = events_matrix[index+k-1]\n",
        "        \n",
        "          event = events_matrix[index+k]\n",
        "\n",
        "          event1 = events_matrix[index+k+1]\n",
        "          event2 = events_matrix[index+k+2]\n",
        "          event3 = events_matrix[index+k+3]\n",
        "          event4 = events_matrix[index+k+4]\n",
        "          global_time = events_matrix[index + (notes_per_slice * number_of_slices)][1] / output_ticks\n",
        "          if relative_note_timings:\n",
        "            #if abs(event1[1]-event[1]) > 0:\n",
        "              #time += int(min(event02[2], event01[2], event0[2], event[2], event1[2], event2[2], event3[2]) * notes_timings_multiplier)\n",
        "              #time += int(min(event[2], event0[2], event1[2]))\n",
        "            if event1[1] != event[1]: \n",
        "              time += abs(output_ticks - int((event[5] + ticks_per_note) * ticks_durations_multiplier))\n",
        "            else:\n",
        "              time += 0\n",
        "          else:\n",
        "            if event1[1] != event[1]:\n",
        "             time += abs(int(ticks_per_note * ticks_durations_multiplier))\n",
        "            else:\n",
        "              time += 0\n",
        "          #ovent_a = ['note', int(time * notes_timings_multiplier), int(event[2] * notes_durations_multiplier), event[3], event[4] + transpose_composition, (int(event4[5] * notes_velocities_multiplier) + transpose_velocity)]\n",
        "          #ovent_a = ['note', int(time * notes_timings_multiplier), int(event4[2] * notes_durations_multiplier), event4[3], event4[4] + transpose_composition, (int(event4[5] * notes_velocities_multiplier) + transpose_velocity)]        \n",
        "          ovent_a = ['note', int(time * notes_timings_multiplier), int(event[2] * notes_durations_multiplier), event[3], event[4] + transpose_composition, (int(event[5] * notes_velocities_multiplier) + transpose_velocity)]                  \n",
        "          output_events_matrix.append(ovent_a)        \n",
        "        \n",
        "        except:\n",
        "          print('The generator had experienced an error')\n",
        "          print('Please try again, maybe even with different parameters or a larger dataset.')\n",
        "          print('If error persists, please restart/factory reset the run-time.')\n",
        "          sys.exit()      \n",
        "      \n",
        "        x += 1\n",
        "\n",
        "  if attention_span == 'augmentation1':\n",
        "    try:\n",
        "      for i in range(len(notes_matrix)-8):\n",
        "        if notes_matrix[i] == event03[4]:\n",
        "          if events_matrix[i][2] == event03[2]:\n",
        "            if events_matrix[i][5] == event03[5]:\n",
        "              if events_matrix[i][3] == event03[3]:                   \n",
        "                if notes_matrix[i+1] == event02[4]:\n",
        "                  #if events_matrix[i+1][2] == event02[2]:\n",
        "                   # if events_matrix[i+1][5] == event02[5]:\n",
        "                   #   if events_matrix[i+1][3] == event02[3]:                     \n",
        "                  if notes_matrix[i+2] == event01[4]:\n",
        "                    if notes_matrix[i+3] == event0[4]:                     \n",
        "                      if notes_matrix[i+4] == event[4]:\n",
        "                        if notes_matrix[i+5] == event1[4]:\n",
        "                          if notes_matrix[i+6] == event2[4]:\n",
        "                            if notes_matrix[i+7] == event3[4]:\n",
        "                              if notes_matrix[i+8] == event4[4]:\n",
        "                                index = i + 8\n",
        "\n",
        "\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "      \n",
        "  if attention_span == 'augmentation2':\n",
        "    try:\n",
        "      for i in range(len(notes_matrix)-8):\n",
        "        if notes_matrix[i] == event03[4]:\n",
        "          if events_matrix[i][2] == event03[2]:\n",
        "            if events_matrix[i][5] == event03[5]:\n",
        "              if events_matrix[i][3] == event03[3]:                   \n",
        "                if notes_matrix[i+1] == event02[4]:\n",
        "                  if events_matrix[i+1][2] == event02[2]:\n",
        "                    if events_matrix[i+1][5] == event02[5]:\n",
        "                      if events_matrix[i+1][3] == event02[3]:                     \n",
        "                        if notes_matrix[i+2] == event01[4]:\n",
        "                          if notes_matrix[i+3] == event0[4]:                     \n",
        "                            if notes_matrix[i+4] == event[4]:\n",
        "                              if notes_matrix[i+5] == event1[4]:\n",
        "                                if notes_matrix[i+6] == event2[4]:\n",
        "                                  if notes_matrix[i+7] == event3[4]:\n",
        "                                    if notes_matrix[i+8] == event4[4]:\n",
        "                                      index = i + 8\n",
        "\n",
        "\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "\n",
        "if melody_only_output_for_melody_datasets:   \n",
        "  events_matrix = [output_ticks, slices_melody_events]\n",
        "  itrack = 1\n",
        "  i=0\n",
        "  while itrack < len(events_matrix):\n",
        "    for event in events_matrix[itrack]:\n",
        "      if i >= index1 and i < index1 + number_of_slices * notes_per_slice:\n",
        "        if event[0] == 'note':\n",
        "\n",
        "          output_r.append(event)\n",
        "          event[2] = ticks_per_note\n",
        "          output1.append(event)\n",
        "          x+=1\n",
        "      i+=1\n",
        "    itrack += 1\n",
        "  output.append(output1)\n",
        "\n",
        "output += [output_events_matrix]\n",
        "\n",
        "midi_data = MIDI.opus2midi(MIDI.score2opus(output))\n",
        "\n",
        "if not relative_note_timings:\n",
        "  with open('output-absolute.mid', 'wb') as midi_file1:\n",
        "      midi_file1.write(midi_data)\n",
        "      midi_file1.close()\n",
        "else:\n",
        "  with open('output-relative.mid', 'wb') as midi_file1:\n",
        "    midi_file1.write(midi_data)\n",
        "    midi_file1.close()\n",
        "\n",
        "print('First Note:', output[2][1], '=== Last Note:', output[2][-1])\n",
        "print('MIDI Stats:', MIDI.score2stats(output))\n",
        "print('Total notes:', x, 'out of expected:', len(output[2]) - len(cnotes_matrix) - 1)\n",
        "print('Done!')\n",
        "print('Downloading your MIDI now :)')\n",
        "from google.colab import files\n",
        "if not relative_note_timings:\n",
        "  files.download('/content/output-absolute.mid')\n",
        "else:\n",
        "  files.download('/content/output-relative.mid')\n",
        "#files.download('/content/output-relative.mid')\n",
        "print('Enjoy! :)')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbK4CaUQOjvW"
      },
      "source": [
        "# Fun MIR stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJIcrVY6o9Gu",
        "cellView": "form"
      },
      "source": [
        "#@title Basic statistical analysis of the output MIDI file\n",
        "\n",
        "MIDI_DIR = \"/content/*.mid\"\n",
        "### https://github.com/brennan2602/FYP\n",
        "\n",
        "\n",
        "def get_piano_roll(midifile):\n",
        "\tmidi_pretty_format = pretty_midi.PrettyMIDI(midifile)\n",
        "\tpiano_midi = midi_pretty_format.instruments[0] # Get the piano channels\n",
        "\tpiano_roll = piano_midi.get_piano_roll(fs=20)\n",
        "\treturn piano_roll\n",
        "\n",
        "#uses split encoding scheme (here only encoding the note values)\n",
        "#works by looping through time increments of the piano roll array and writing the notes being played\n",
        "#at a given time sample as a number on the corresponding line of a string # is written when no notes played for that\n",
        "#sample\n",
        "def encode(arr):\n",
        "    timeinc=0\n",
        "    outString=\"\"\n",
        "    for time in arr:\n",
        "        notesinc = -1\n",
        "        #print(time)\n",
        "        if np.all(time==0):\n",
        "            outString=outString+\"#\"\n",
        "        for vel in arr[timeinc]:\n",
        "            notesinc=notesinc+1\n",
        "            if vel != 0:\n",
        "                noteRep=str(notesinc) + \" \"\n",
        "                #print(noteRep)\n",
        "                outString=outString+noteRep\n",
        "        outString=outString+\"\\n\"\n",
        "        timeinc = timeinc+1\n",
        "    return outString\n",
        "\n",
        "\n",
        "def getSilences(test):\n",
        "    test=test[:-1] #removing last line in string (always blank)\n",
        "    output=test.split(\"\\n\") #splitting into array\n",
        "    res = len(output)\n",
        "    #initialising counters\n",
        "    maxcounter=0\n",
        "    counter=0\n",
        "    silenceCount=0\n",
        "\n",
        "    for x in output:\n",
        "        if x == \"#\": #when a \"#\" is seen nothing is being played that sample\n",
        "            counter=counter+1 #this tracks a streak of silences\n",
        "            silenceCount+=1 #this tracks total silences\n",
        "        if x != \"#\":\n",
        "            counter=0 #reseting streak\n",
        "        if counter>maxcounter:\n",
        "            maxcounter=counter #updating longest silence streak when appropriate\n",
        "    return maxcounter,silenceCount\n",
        "\n",
        "\n",
        "#by looking at the length of song and the amount of silences this returns % silence\n",
        "def getPercentSilence(gen,silences):\n",
        "    test = gen\n",
        "    test = test[:-1]\n",
        "    output = test.split(\"\\n\")\n",
        "    res = len(output)\n",
        "    percent=silences/res\n",
        "    return percent\n",
        "\n",
        "\n",
        "def getStatsNotes(test):\n",
        "    test=test[:-1] #get rid of blank line at the end\n",
        "    notes=[]\n",
        "    output = test.split(\"\\n\") #split string on new lines\n",
        "\n",
        "    #initial values updated while looping through\n",
        "    maxPerSamp=0\n",
        "    silenceSamp=0\n",
        "    notesPlayed=0\n",
        "    maxNotes=0\n",
        "    maxVal=0\n",
        "    minVal=127\n",
        "\n",
        "    for x in output:\n",
        "        samp=x.split(\" \")\n",
        "        samp=samp[:-1] #theres a blank result at the end of array from split this indexing removes it\n",
        "        while \"0\" in samp:\n",
        "            samp.remove(\"0\") #sometimes 0 samples exist this removes them as they aren't notes played\n",
        "        if len(samp)==0:\n",
        "            silenceSamp+=1 #counting silences\n",
        "        notesPlayed=notesPlayed+len(samp) #counting notes played\n",
        "        if len(samp)>0:\n",
        "            #getting max and min note values at this time step\n",
        "            minimum=min(samp)\n",
        "            maximum=max(samp)\n",
        "            #updating max and min values note values for song if appropriate\n",
        "            if int(minimum)<minVal:\n",
        "                minVal=int(minimum)\n",
        "            if int(maximum)>maxVal:\n",
        "                maxVal=int(maximum)\n",
        "        #updating maximum number of notes per sample if appropriate\n",
        "        if len(samp)>maxNotes:\n",
        "            maxNotes=len(samp)\n",
        "    rangeNotes=maxVal-minVal #spread of notes\n",
        "    avgNotes = notesPlayed / len(output) #average notes per sample\n",
        "    adjNotes=notesPlayed /(len(output)-silenceSamp) #average notes per sample adjusted to remove silent samples\n",
        "    return rangeNotes, maxVal, minVal,maxNotes,avgNotes,adjNotes\n",
        "\n",
        "\n",
        "files=glob.glob(MIDI_DIR)#point towards directory with midi files (here same folder)\n",
        "#print(files)\n",
        "\n",
        "for f in files:\n",
        "    print(f)\n",
        "    pr = get_piano_roll(f) #gets piano roll representation of the midi file\n",
        "    arr = pr.T\n",
        "    outString= encode(arr) #gets a string representation of the midi file\n",
        "    maxsilences, silences = getSilences(outString) #by passing in the encoded string get longest silence and the total\n",
        "                                                   #number of samples which are silent\n",
        "    noteRange, maxVal, minVal, maxNotes, avgNotes, adjAvg =getStatsNotes(outString) # getting some stats by looping\n",
        "                                                                                    # through encoded data\n",
        "    percentSilence= getPercentSilence(outString,silences) # get % silence from silence / outString length\n",
        "\n",
        "    #printing out to the user\n",
        "    print(\"longest silence is \",maxsilences,\"samples long\")\n",
        "    print(\"silence covers:\",round(percentSilence,4),\"%\")\n",
        "    print(\"notes span range:\",noteRange)\n",
        "    print(\"max note value:\",maxVal)\n",
        "    print(\"min note value:\",minVal)\n",
        "    print(\"average number of notes per sample:\",round(avgNotes,4))\n",
        "    print(\"average number of notes per sample (adjusted to remove silence samples):\",round(adjAvg,4))\n",
        "    print(\"max number of notes played in a sample:\",maxNotes)\n",
        "    print(\"\\n\")\n",
        "\n",
        "#NOTE some minor discrepencies vs reading in from generated file directly\n",
        "#However this does provide a uniform check to use for songs generated by both encoding schemes\n",
        "#Can also be used to evaluate training file\n",
        "#uses split encoding to get the text representation for ease of development"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "4UWsfXb2sla1"
      },
      "source": [
        "#@title Basic graph of the last output\n",
        "seconds_to_show = 30 #@param {type:\"slider\", min:1, max:180, step:1}\n",
        "show_whole_track = False #@param {type:\"boolean\"}\n",
        "graph_color = \"red\" #@param [\"blue\", \"red\", \"green\"]\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "z = []\n",
        "\n",
        "t = 0\n",
        "itrack = 1\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "while itrack < len(output1):\n",
        "  for event in output1[itrack]:\n",
        "      if event[0] == 'note':\n",
        "        y.append(event[4])\n",
        "        x.append(t)\n",
        "        plt.plot(x, y, color=graph_color)\n",
        "        t += 0.25       \n",
        "        if not show_whole_track:\n",
        "          if t == seconds_to_show: break\n",
        "  itrack +=1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "J-mpUZFB02Da"
      },
      "source": [
        "#@title Output MIDI bokeh plot\n",
        "\n",
        "preset = Preset(plot_width=850)\n",
        "plotter = Plotter(preset, plot_max_length_bar=4)\n",
        "\n",
        "if not relative_note_timings:\n",
        "  pm = PrettyMIDI(\"/content/output-absolute.mid\")\n",
        "else:\n",
        "  pm = PrettyMIDI(\"/content/output-relative.mid\")\n",
        "plotter.show_notebook(pm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "n9uT8VexhsxT"
      },
      "source": [
        "#@title Bonus Music21 Graphs (slow)\n",
        "display_relative_output = True\n",
        "histogram_pitchSpace_count = False #@param {type:\"boolean\"}\n",
        "histogram_pitchClass_count = False #@param {type:\"boolean\"}\n",
        "Windowed_Keys = False #@param {type:\"boolean\"}\n",
        "scatter_quarterLength_pitchSpace = False #@param {type:\"boolean\"}\n",
        "quarterLength_3DBars_pitchSpace_count = True #@param {type:\"boolean\"}\n",
        "\n",
        "if relative_note_timings:\n",
        "  s = converter.parse(\"/content/output-relative.mid\")\n",
        "else:\n",
        "  s = converter.parse(\"/content/output-absolute.mid\")\n",
        "p = 0\n",
        "if histogram_pitchSpace_count:\n",
        "  p = music21.graph.plot.HistogramPitchSpace(s)\n",
        "  p.id\n",
        "  'histogram-pitchSpace-count'\n",
        "  p.run()  # with defaults and proper configuration, will open graph\n",
        "\n",
        "if histogram_pitchClass_count:\n",
        "  p = graph.plot.HistogramPitchClass(s)\n",
        "  p.id\n",
        "  'histogram-pitchClass-count'\n",
        "  p.run()\n",
        "\n",
        "if Windowed_Keys:\n",
        "  p = graph.plot.WindowedKey(s.parts[0])\n",
        "  p.id\n",
        "  p.run()\n",
        "\n",
        "if scatter_quarterLength_pitchSpace:\n",
        "  p = graph.plot.ScatterPitchSpaceQuarterLength(s)\n",
        "  p.id\n",
        "  'scatter-quarterLength-pitchSpace'\n",
        "  p.run()\n",
        "if quarterLength_3DBars_pitchSpace_count:\n",
        "  p = graph.plot.Plot3DBarsPitchSpaceQuarterLength(s)\n",
        "  p.id\n",
        "  '3DBars-quarterLength-pitchSpace-count'\n",
        "  p.run()\n",
        "if p == 0:\n",
        "  print('Please select graph(s) to plot, please :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Snu3fb4N-Nd"
      },
      "source": [
        "# Congrats! :) You did it :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxsedAQbS_wR",
        "cellView": "form"
      },
      "source": [
        "#@title Make a nice Arc diagram of the output to show friends and family :)\n",
        "MIDI_file_track_to_visualize = 1 #@param {type:\"number\"}\n",
        "multi_track_input = True\n",
        "\n",
        "midi_file = '/content/output-absolute.mid'\n",
        "plot_title = \"Meddleying MAESTRO Output Arc Diagram\"\n",
        "\n",
        "def maximal_matching_pair( s, substring_length, old_index=-1 ):\n",
        "    '''\n",
        "    find the first pair of matching substrings at least as long as the specified length\n",
        "    '''\n",
        "    if substring_length > len(s)/2:\n",
        "        return (len(substring_length), -1) # fail- futile to keep searching with this string\n",
        "\n",
        "    head = s[:substring_length]\n",
        "    tail = s[substring_length:]\n",
        "    index = tail.find(head) \n",
        "    if index == -1:\n",
        "        if substring_length > 2:\n",
        "            return (substring_length-1, old_index) # success\n",
        "        return (substring_length, index) # fail- failed on first 2 character substring attempt \n",
        "    \n",
        "    return maximal_matching_pair(s, substring_length+1, index) # keep looking\n",
        "\n",
        "def first_matching_substring_pair( s, start=0 ):\n",
        "    '''\n",
        "    returns the first matching substring pair of at least length 2 in the given string, \n",
        "    ignoring all characters of the string before the given start index \n",
        "    '''\n",
        "    if start < 0:\n",
        "        return () # invalid input: start must be non-negative\n",
        "\n",
        "    if len(s[start:]) < 4:\n",
        "        return () # fail: string too short to find matching substrings of minimal length 2\n",
        "\n",
        "    minimal_substring_length = 2\n",
        "    (length, distance) = maximal_matching_pair(s[start:], minimal_substring_length)\n",
        "    if distance != -1:\n",
        "        return (start, length, distance) # success\n",
        "    \n",
        "    return first_matching_substring_pair(s, start+1) # keep looking\n",
        "\n",
        "def matching_substring_pairs( string ):\n",
        "    '''\n",
        "    returns a collection of consecutive substring pairs encoded as (start, length, distance) where\n",
        "    * start is the index of the first character of the first substring of the matching substring pair,\n",
        "    * length is the length of the substrings in the matching substring pair, and\n",
        "    * distance is the distance from the end of the first substring to the begining of the second substring\n",
        "    '''\n",
        "    pairs = []\n",
        "    pair = first_matching_substring_pair(string, 0)\n",
        "    while pair:\n",
        "        pairs.append(pair)\n",
        "        (start, length, distance) = pair\n",
        "        pair = first_matching_substring_pair(string, start+length)\n",
        "    return pairs\n",
        "\n",
        "def plot_arc_diagram( string, plot_title=\"\" ):\n",
        "    slds = matching_substring_pairs(string)\n",
        "    bews = map( lambda sld: (sld[0], sum(sld)+sld[1], sld[1]), slds )\n",
        "    plot_arc_diagram_impl(bews, plot_title)\n",
        "\n",
        "#  begin                                        end                 \n",
        "# /                                            /\n",
        "# ***********-----------O-----------***********\n",
        "# |--width--|            \\          |--width--|\n",
        "#           |-inner rad-| \\\n",
        "# |-----outer radius----|  center\n",
        "\n",
        "def plot_ring( ax, begin, end, width ):\n",
        "    cx = 0.5*(begin + end)\n",
        "    center = (cx, 0)\n",
        "    outer_radius = cx - begin\n",
        "    inner_radius = outer_radius - width\n",
        "\n",
        "    mypie, _ = ax.pie([1], radius=outer_radius, colors=[(0.4,0.4, 1.0, 0.3)], center=center )\n",
        "    plt.setp( mypie, width=width)\n",
        "\n",
        "    return outer_radius\n",
        "\n",
        "def plot_arc_diagram_impl( bews, plot_title ):\n",
        "    fig, ax = plt.subplots(subplot_kw={'aspect': 'auto'})\n",
        "\n",
        "    x_min = 0\n",
        "    x_max = 1920\n",
        "    max_width = 1080\n",
        "    for bew in bews:\n",
        "        x_max = max(x_max, bew[1])\n",
        "        orad = plot_ring(ax, bew[0], bew[1], bew[2])\n",
        "        max_width = max(max_width, orad)\n",
        "\n",
        "    ax.set_xlim(x_min, x_max)\n",
        "    ax.set_ylim( -max_width, max_width)\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    title_obj = plt.title(plot_title, loc='center')\n",
        "    plt.setp(title_obj, color=(0.0, 0.0, 0.0, 1)) \n",
        "\n",
        "    plt.savefig('/content/output.png', dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def stringify_notes(midi_file, track_number):\n",
        "\n",
        "    mid = MidiFile(midi_file)\n",
        "    track_notes = {}\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        track_notes[i] = ''\n",
        "        for msg in track:\n",
        "            if( msg.type == 'note_on'):\n",
        "                track_notes[i] += str(msg.note) +'n'\n",
        "            if( msg.type == 'note_off'):\n",
        "                track_notes[i] += str(msg.note) +'f'\n",
        "    return track_notes[track_number]\n",
        "\n",
        "if multi_track_input:\n",
        "  try:\n",
        "    plot_arc_diagram(stringify_notes(midi_file, MIDI_file_track_to_visualize), plot_title)\n",
        "    if debug: \n",
        "      print('Debug mode')\n",
        "    print('MIDI Track #', MIDI_file_track_to_visualize, 'Arc Diagram')\n",
        "    Image('output-absolute.png')\n",
        "  except:\n",
        "    print('Error in processing your MIDI file. Sorry.')\n",
        "    sys.exit\n",
        "from google.colab import files\n",
        "files.download('/content/output.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA6K04h9OpK8"
      },
      "source": [
        "# MIDI Patch Numbers Reference Chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fRNHIhVkI85"
      },
      "source": [
        "***\n",
        "\n",
        "## General MIDI Level 1 Instrument Families\n",
        "\n",
        "### The General MIDI Level 1 instrument sounds are grouped by families. In each family are 8 specific instruments.\n",
        "\n",
        "https://www.midi.org/specifications-old/item/gm-level-1-sound-set\n",
        "\n",
        "***\n",
        "\n",
        "## PC #\tFamily Name\n",
        "\n",
        "1-8\tPiano\n",
        "\n",
        "9-16\tChromatic Percussion\n",
        "\n",
        "17-24\tOrgan\n",
        "\n",
        "25-32\tGuitar\n",
        "\n",
        "33-40\tBass\n",
        "\n",
        "41-48\tStrings\n",
        "\n",
        "49-56\tEnsemble\n",
        "\n",
        "57-64\tBrass\n",
        "\n",
        "65-72\tReed\n",
        "\n",
        "73-80\tPipe\n",
        "\n",
        "81-88\tSynth Lead\n",
        "\n",
        "89-96\tSynth Pad\n",
        "\n",
        "97-104\tSynth Effects\n",
        "\n",
        "105-112\tEthnic\n",
        "\n",
        "113-120\tPercussive\n",
        "\n",
        "121-128\tSound Effects\n",
        "\n",
        "***\n",
        "\n",
        "Note: While GM1 does not define the actual characteristics of any sounds, the names in parentheses after each of the synth leads, pads, and sound effects are, in particular, intended only as guides).\n",
        "\n",
        "***\n",
        "\n",
        "### PC #\tInstrument Name \n",
        "#### Subtract 1 from MIDI patch index number below to get MIDI patch number to use\n",
        "1.\tAcoustic Grand Piano\n",
        "2.\tBright Acoustic Piano\n",
        "3.\tElectric Grand Piano\n",
        "4.\tHonky-tonk Piano\n",
        "5.\tElectric Piano 1\n",
        "6.\tElectric Piano 2\n",
        "7.\tHarpsichord\n",
        "8.\tClavi\n",
        "9.\tCelesta\n",
        "10.\tGlockenspiel\n",
        "11.\tMusic Box\n",
        "12.\tVibraphone\n",
        "13.\tMarimba\n",
        "14.\tXylophone\n",
        "15.\tTubular Bells\n",
        "16.\tDulcimer\n",
        "17.\tDrawbar Organ\n",
        "18.\tPercussive Organ\n",
        "19.\tRock Organ\n",
        "20.\tChurch Organ\n",
        "21.\tReed Organ\n",
        "22.\tAccordion\n",
        "23.\tHarmonica\n",
        "24.\tTango Accordion\n",
        "25.\tAcoustic Guitar (nylon)\n",
        "26.\tAcoustic Guitar (steel)\n",
        "27.\tElectric Guitar (jazz)\n",
        "28.\tElectric Guitar (clean)\n",
        "29.\tElectric Guitar (muted)\n",
        "30.\tOverdriven Guitar\n",
        "31.\tDistortion Guitar\n",
        "32.\tGuitar harmonics\n",
        "33.\tAcoustic Bass\n",
        "34.\tElectric Bass (finger)\n",
        "35.\tElectric Bass (pick)\n",
        "36.\tFretless Bass\n",
        "37.\tSlap Bass 1\n",
        "38.\tSlap Bass 2\n",
        "39.\tSynth Bass 1\n",
        "40.\tSynth Bass 2\n",
        "41.\tViolin\n",
        "42.\tViola\n",
        "43.\tCello\n",
        "44.\tContrabass\n",
        "45.\tTremolo Strings\n",
        "46.\tPizzicato Strings\n",
        "47.\tOrchestral Harp\n",
        "48.\tTimpani\n",
        "49.\tString Ensemble 1\n",
        "50.\tString Ensemble 2\n",
        "51.\tSynthStrings 1\n",
        "52.\tSynthStrings 2\n",
        "53.\tChoir Aahs\n",
        "54.\tVoice Oohs\n",
        "55.\tSynth Voice\n",
        "56.\tOrchestra Hit\n",
        "57.\tTrumpet\n",
        "58.\tTrombone\n",
        "59.\tTuba\n",
        "60.\tMuted Trumpet\n",
        "61.\tFrench Horn\n",
        "62.\tBrass Section\n",
        "63.\tSynthBrass 1\n",
        "64.\tSynthBrass 2\n",
        "65.\tSoprano Sax\n",
        "66.\tAlto Sax\n",
        "67.\tTenor Sax\n",
        "68.\tBaritone Sax\n",
        "69.\tOboe\n",
        "70.\tEnglish Horn\n",
        "71.\tBassoon\n",
        "72.\tClarinet\n",
        "73.\tPiccolo\n",
        "74.\tFlute\n",
        "75.\tRecorder\n",
        "76.\tPan Flute\n",
        "77.\tBlown Bottle\n",
        "78.\tShakuhachi\n",
        "79.\tWhistle\n",
        "80.\tOcarina\n",
        "81.\tLead 1 (square)\n",
        "82.\tLead 2 (sawtooth)\n",
        "83.\tLead 3 (calliope)\n",
        "84.\tLead 4 (chiff)\n",
        "85.\tLead 5 (charang)\n",
        "86.\tLead 6 (voice)\n",
        "87.\tLead 7 (fifths)\n",
        "88.\tLead 8 (bass + lead)\n",
        "89.\tPad 1 (new age)\n",
        "90.\tPad 2 (warm)\n",
        "91.\tPad 3 (polysynth)\n",
        "92.\tPad 4 (choir)\n",
        "93.\tPad 5 (bowed)\n",
        "94.\tPad 6 (metallic)\n",
        "95.\tPad 7 (halo)\n",
        "96.\tPad 8 (sweep)\n",
        "97.\tFX 1 (rain)\n",
        "98.\tFX 2 (soundtrack)\n",
        "99.\tFX 3 (crystal)\n",
        "100.\tFX 4 (atmosphere)\n",
        "101.\tFX 5 (brightness)\n",
        "102.\tFX 6 (goblins)\n",
        "103.\tFX 7 (echoes)\n",
        "104.\tFX 8 (sci-fi)\n",
        "105.\tSitar\n",
        "106.\tBanjo\n",
        "107.\tShamisen\n",
        "108.\tKoto\n",
        "109.\tKalimba\n",
        "110.\tBag pipe\n",
        "111.\tFiddle\n",
        "112.\tShanai\n",
        "113.\tTinkle Bell\n",
        "114.\tAgogo\n",
        "115.\tSteel Drums\n",
        "116.\tWoodblock\n",
        "117.\tTaiko Drum\n",
        "118.\tMelodic Tom\n",
        "119.\tSynth Drum\n",
        "120.\tReverse Cymbal\n",
        "121.\tGuitar Fret Noise\n",
        "122.\tBreath Noise\n",
        "123.\tSeashore\n",
        "124.\tBird Tweet\n",
        "125.\tTelephone Ring\n",
        "126.\tHelicopter\n",
        "127.\tApplause\n",
        "128.\tGunshot\n",
        "\n",
        "\n"
      ]
    }
  ]
}