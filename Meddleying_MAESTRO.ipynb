{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Meddleying MAESTRO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Meddleying-MAESTRO/blob/main/Meddleying_MAESTRO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA0W-VK1JVQl"
      },
      "source": [
        "# Meddleying MAESTRO (ver 2.1)\n",
        "\n",
        "***\n",
        "\n",
        "## A full-featured Algorithmic Intelligence music generator with full multi-instrument MIDI support.\n",
        "\n",
        "***\n",
        "\n",
        "### Project Los Angeles\n",
        "\n",
        "### Tegridy Code 2020\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eftzIVKrqR5S"
      },
      "source": [
        "# Setup Environment, clone needed code, and install all required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsUtsJGNz6f2",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "!pip install pretty_midi\n",
        "\n",
        "!curl -L \"https://github.com/asigalov61/MIDI-TXT-MIDI/raw/master/MIDI.py\" > 'MIDI.py'\n",
        "\n",
        "!mkdir '/content/Dataset/'\n",
        "!mkdir '/content/C_Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8B3p6QySmE",
        "cellView": "form"
      },
      "source": [
        "#@title Import all modules\n",
        "import glob\n",
        "import os\n",
        "import music21\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "import tqdm.auto\n",
        "import secrets\n",
        "import pretty_midi\n",
        "from google.colab import output, drive\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from mido import MidiFile\n",
        "from IPython.display import display, Image\n",
        "import MIDI\n",
        "\n",
        "ticks_per_note = 50\n",
        "ctime = 0\n",
        "cev_matrix = []\n",
        "cnotes_matrix = []\n",
        "debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Pv5eNRqiyr"
      },
      "source": [
        "# Select and download a sample MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bFuzEwrshWCk"
      },
      "source": [
        "#@title (Best Choice/Multi-Instrumental) Processed ready-to-use Special Tegridy Multi-Instrumental Dataset\n",
        "%cd /content/\n",
        "!wget 'https://github.com/asigalov61/Meddleying-MAESTRO/raw/main/Meddleying-MAESTRO-Music-Dataset.data'\n",
        "#!unzip -j Meddleying-MAESTRO-Music-Dataset.data\n",
        "#!rm Meddleying-MAESTRO-Music-Dataset.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh0fYeVMITLY",
        "cellView": "form"
      },
      "source": [
        "#@title (BEST Choice / Multi-Intrumental) Special Tegridy MIDI DataSet (~325 MIDIs) \n",
        "%cd /content/Dataset/\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!unzip -j 'Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!rm 'Tegridy-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhf6GtCGIbJU",
        "cellView": "form"
      },
      "source": [
        "#@title (Piano Performance Dataset) Download Google Magenta MAESTRO v.2.0.0 Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Dataset/\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip\n",
        "!rm maestro-v2.0.0-midi.zip\n",
        "%cd /content/Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "S4oa9lUWLPN5"
      },
      "source": [
        "#@title A simple code to unzip MIDI datasets without any hastle\n",
        "!mkdir /content/Dataset/\n",
        "%cd /content/Dataset/\n",
        "!unzip -j /content/Dataset/*.zip\n",
        "!rm /content/Dataset/*.zip\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jsEXxkDLQ9Z"
      },
      "source": [
        "# Process MIDI Dataset to MIDI Notes and MIDI Events Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYHrPooT8Oq2",
        "cellView": "form"
      },
      "source": [
        "#@title Please note that transpose function reduces MIDIs to Piano only. Sliding sliders to minimum value disables slider's option. Standard MIDI timings are 400/120\n",
        "full_path_to_output_dataset_to = \"/content/Meddleying-MAESTRO-Music-Dataset.data\" #@param {type:\"string\"}\n",
        "transpose_MIDIs_to_one_key = False #@param {type:\"boolean\"}\n",
        "desired_MIDI_channel = 16 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "flip_input_dataset = False #@param {type:\"boolean\"}\n",
        "remove_drums = False #@param {type:\"boolean\"}\n",
        "flip_notes = False #@param {type:\"boolean\"}\n",
        "remove_random_notes = False #@param {type:\"boolean\"}\n",
        "remove_every_nth_note = 0 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "remove_every_randomth_note = False #@param {type:\"boolean\"}\n",
        "constant_notes_duration_time_ms = 0 #@param {type:\"slider\", min:0, max:800, step:100}\n",
        "five_notes_per_octave_pitch_quantization = False #@param {type:\"boolean\"}\n",
        "octave_channel_split = False #@param {type:\"boolean\"}\n",
        "simulated_velocity = True\n",
        "simulated_velocity_volume = 2 #@param {type:\"slider\", min:2, max:127, step:1}\n",
        "simulated_velocity_range = 1 #@param {type:\"slider\", min:1, max:127, step:1}\n",
        "transpose_notes_pitch = 0 #@param {type:\"integer\"}\n",
        "reverse_output_dataset = False #@param {type:\"boolean\"}\n",
        "combine_reversed_and_original_datasets_together = False #@param {type:\"boolean\"}\n",
        "\n",
        "debug = False\n",
        "\n",
        "os.chdir(\"/content/\")\n",
        "\n",
        "ev_matrix = []\n",
        "rev_matrix = []\n",
        "not_matrix = []\n",
        "rnot_matrix = []\n",
        "durations_matrix = []\n",
        "velocities_matrix = []\n",
        "files_count = 0\n",
        "remnote = 0\n",
        "remnote_count = 0\n",
        "notes_counter = 0\n",
        "every_random_note = 7\n",
        "\n",
        "print('Now processing the matrices. Sorting and normalizing.')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "print('Please stand-by...')\n",
        "\n",
        "#converts all midi files in the current folder\n",
        "#converting everything into the key of C major or A minor\n",
        "# major conversions\n",
        "\n",
        "if transpose_MIDIs_to_one_key :\n",
        "\n",
        "  majors = dict([(\"A-\", 4),(\"A\", 3),(\"B-\", 2),(\"B\", 1),(\"C\", 0),(\"D-\", -1),(\"D\", -2),(\"E-\", -3),(\"E\", -4),(\"F\", -5),(\"G-\", 6),(\"G\", 5)])\n",
        "  minors = dict([(\"A-\", 1),(\"A\", 0),(\"B-\", -1),(\"B\", -2),(\"C\", -3),(\"D-\", -4),(\"D\", -5),(\"E-\", 6),(\"E\", 5),(\"F\", 4),(\"G-\", 3),(\"G\", 2)])\n",
        "\n",
        "\n",
        "  os.chdir(\"/content/Dataset/\")\n",
        "\n",
        "  print('Converting all possible MIDI files to C Key.')\n",
        "  print('This may take a while. Please wait...')\n",
        "\n",
        "  for file in tqdm.auto.tqdm(glob.glob(\"*.mid\")):\n",
        "    try:\n",
        "      score = music21.converter.parse(file)\n",
        "      key = score.analyze('key')\n",
        "\n",
        "      #print('Detected Key:', key.tonic.name, key.mode)\n",
        "\n",
        "      if key.mode == \"major\":\n",
        "            halfSteps = majors[key.tonic.name]\n",
        "            \n",
        "      elif key.mode == \"minor\":\n",
        "            halfSteps = minors[key.tonic.name]\n",
        "\n",
        "      newscore = score.transpose(halfSteps)\n",
        "      key = newscore.analyze('key')\n",
        "      #print('Detected Key:', key.tonic.name, key.mode)\n",
        "      newFileName = \"/content/C_Dataset/C_\" + file\n",
        "      newscore.write('midi',newFileName)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "os.chdir(\"/content/\")\n",
        "\n",
        "print('Enumerating final matrices...')\n",
        "\n",
        "if not transpose_MIDIs_to_one_key :\n",
        "  dataset_addr = \"Dataset\"\n",
        "else:\n",
        "  dataset_addr = \"C_Dataset\"\n",
        "files = os.listdir(dataset_addr)\n",
        "\n",
        "for file in tqdm.auto.tqdm(files):\n",
        "    file_address = os.path.join(dataset_addr, file)\n",
        "    \n",
        "    score = []\n",
        "\n",
        "    midi_file = open(file_address, 'rb')\n",
        "    if debug: print('Processing File:', file_address)\n",
        "\n",
        "    score2 = MIDI.midi2opus(midi_file.read())\n",
        "    score1 = MIDI.to_millisecs(score2)\n",
        "    score3 = MIDI.opus2score(score1)\n",
        "    score = score3\n",
        "    midi_file.close()\n",
        "\n",
        "    if remove_drums:\n",
        "      score4 = MIDI.grep(score3, [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15])\n",
        "    else:\n",
        "      score4 = score3\n",
        "  \n",
        "    if desired_MIDI_channel < 16:\n",
        "      score = MIDI.grep(score4, [desired_MIDI_channel-1])\n",
        "    else:\n",
        "      score = score4\n",
        "    \n",
        "    itrack = 1\n",
        "    while itrack < len(score):\n",
        "        for event in score[itrack]:\n",
        "          if event[0] == 'note':\n",
        "            if flip_input_dataset:\n",
        "              event[4] = 127 - event[4]\n",
        "\n",
        "            if five_notes_per_octave_pitch_quantization:\n",
        "              event[4] = int(math.floor(event[4] / 12 * 5) * 12 / 5)\n",
        "            \n",
        "            if octave_channel_split:\n",
        "              event[4] = int((event[4] + (event[3] - 4) * 12) % (127 - 12 * 2))\n",
        "            \n",
        "            if simulated_velocity_volume > 2 and simulated_velocity_range > 1: \n",
        "              event[5] = simulated_velocity_volume + secrets.randbelow(simulated_velocity_range)\n",
        "            \n",
        "            if constant_notes_duration_time_ms > 0:\n",
        "              event[2] = constant_notes_duration_time_ms\n",
        "            \n",
        "            if transpose_notes_pitch:\n",
        "              event[4] = event[4] + transpose_notes_pitch\n",
        "            \n",
        "            if flip_notes:\n",
        "              event[4] = 127 - event[4]\n",
        "\n",
        "            notes_counter += 1\n",
        "            \n",
        "            if remove_random_notes:\n",
        "              if secrets.randbelow(2) == 1:\n",
        "                remnote_count += 1\n",
        "              else:\n",
        "                not_matrix.append(event[4])\n",
        "                ev_matrix.append(event)\n",
        "                continue\n",
        "                  \n",
        "            if remove_every_nth_note > 0:\n",
        "              if remnote == remove_every_nth_note + 1:\n",
        "                remnote = 0 \n",
        "                remnote_count += 1\n",
        "              else:\n",
        "                remnote += 1\n",
        "                not_matrix.append(event[4])\n",
        "                ev_matrix.append(event)\n",
        "                continue\n",
        "\n",
        "            if remove_every_randomth_note:\n",
        "              if remnote == every_random_note + 1:\n",
        "                remnote = 0\n",
        "                remnote_count += 1\n",
        "                every_random_note = secrets.randbelow(every_random_note+2)\n",
        "              else:\n",
        "                remnote += 1\n",
        "                not_matrix.append(event[4])\n",
        "                ev_matrix.append(event)\n",
        "                continue\n",
        "            else:\n",
        "              not_matrix.append(event[4])\n",
        "              ev_matrix.append(event)            \n",
        "\n",
        "        itrack += 1        \n",
        "\n",
        "    # Calculate stats about the resulting dataset\n",
        "    \n",
        "    average_note_pitch = 0\n",
        "    min_note = 0\n",
        "    max_note = 0\n",
        "    itrack = 1\n",
        "    while itrack < len(score):\n",
        "        for event in score[itrack]:\n",
        "          if event[0] == 'note':\n",
        "            average_note_pitch = int(average_note_pitch + event[4]) / 2\n",
        "            min_note = int(min(min_note, event[4]))\n",
        "            max_note = int(max(min_note, event[4]))\n",
        "        itrack += 1\n",
        "\n",
        "    files_count += 1\n",
        "    if debug:\n",
        "      print('File:', midi_file)\n",
        "\n",
        "if reverse_output_dataset:\n",
        "  print('Augmenting the dataset now to reduce plagiarizm and repetitions.')\n",
        "  print('This may take a while on a large dataset so please wait...')\n",
        "  rnot_matrix = not_matrix\n",
        "  rev_matrix = ev_matrix\n",
        "  rnot_matrix.reverse()\n",
        "  rev_matrix.reverse()\n",
        "  not_matrix = rnot_matrix\n",
        "  ev_matrix = rev_matrix\n",
        "if combine_reversed_and_original_datasets_together:\n",
        "  not_matrix += rnot_matrix\n",
        "  ev_matrix += rev_matrix\n",
        "\n",
        "print('Task complete :)')\n",
        "print('==================================================')\n",
        "print('Number of processed dataset MIDI files:', files_count)\n",
        "if reverse_output_dataset: print('The dataset was augmented to prevent plagiarism as requested.')\n",
        "print('Number of notes in the dataset MIDI files:', notes_counter)\n",
        "if remnote_count > 0: print('Number of notes removed:', remnote_count)\n",
        "print('Number of notes in the resulting dataset:', len(not_matrix))\n",
        "#print('Minimum note pitch:', min_note)\n",
        "#print('Maximum note pitch:', max_note)\n",
        "print('Number of total MIDI events recorded:', len(ev_matrix))\n",
        "print('Average note pitch:', average_note_pitch)\n",
        "if remove_drums: print('Drums MIDI events have been removed as requested.')\n",
        "# define a list of places\n",
        "MusicDataset = [not_matrix, ev_matrix]\n",
        "\n",
        "with open(full_path_to_output_dataset_to, 'wb') as filehandle:\n",
        "    # store the data as binary data stream\n",
        "    pickle.dump(MusicDataset, filehandle)\n",
        "print('Dataset was saved at:', full_path_to_output_dataset_to)\n",
        "print('Task complete. Enjoy! :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TUUCQTxWp9U"
      },
      "source": [
        "# Load/Re-load the processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Kv4cUwf8yxJK"
      },
      "source": [
        "#@title Load pre-processed dataset from a file to memory\n",
        "full_path_to_dataset_file = \"/content/Meddleying-MAESTRO-Music-Dataset.data\" #@param {type:\"string\"}\n",
        "\n",
        "not_matrix = []\n",
        "ev_matrix = []\n",
        "\n",
        "with open(full_path_to_dataset_file, 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    MusicDataset = pickle.load(filehandle)\n",
        "    not_matrix = MusicDataset[0]\n",
        "    ev_matrix = MusicDataset[1]\n",
        "\n",
        "print('Task complete. Enjoy! :)')\n",
        "print('==================================================')\n",
        "print('Number of notes in the dataset:', len(not_matrix))\n",
        "print('Number of total MIDI events recorded:', len(ev_matrix))\n",
        "print('Done! Enjoy! :)')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJyApDLFNOwb"
      },
      "source": [
        "# Custom MIDI / priming sequence option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlJ0itWgyA6E",
        "cellView": "form"
      },
      "source": [
        "#@title Enter your custom MIDI selections here\n",
        "full_path_to_MIDI_file = \"/content/seed3.mid\" #@param {type:\"string\"}\n",
        "MIDI_channels_selection = \"all\" #@param [\"all\"] {allow-input: true}\n",
        "start_note_index = 0 #@param {type:\"number\"}\n",
        "end_note_index = 149 #@param {type:\"number\"}\n",
        "score = []\n",
        "ctime = 0\n",
        "midi_file = open(full_path_to_MIDI_file, 'rb')\n",
        "if debug: print('Processing File:', file_address)\n",
        "\n",
        "if MIDI_channels_selection == 'all':\n",
        "  score1 = MIDI.midi2score(midi_file.read())\n",
        "else:\n",
        "  score0 = MIDI.midi2score(midi_file.read())\n",
        "  score1 = MIDI.grep(score0, [int(MIDI_channels_selection)])\n",
        "midi_file.close()\n",
        "score2 = MIDI.score2opus(score1)\n",
        "score3 = MIDI.to_millisecs(score2)\n",
        "score = MIDI.opus2score(score3)\n",
        "cnotes_matrix = []\n",
        "cev_matrix = []\n",
        "x = 0\n",
        "itrack = 1\n",
        "while itrack < len(score):\n",
        "    for event in score[itrack]:\n",
        "       if event[0] == 'note':\n",
        "          if x >= start_note_index and x <= end_note_index: \n",
        "            cnotes_matrix.append(event[4])\n",
        "          if x >= start_note_index and x <= end_note_index:    \n",
        "            cev_matrix.append(['note', ctime, event[2], event[3], event[4], event[5]])\n",
        "            #ctime += ticks_per_note\n",
        "            ctime = event[1]\n",
        "          x += 1\n",
        "    itrack += 1\n",
        "  \n",
        "if debug:\n",
        "  print('File:', midi_file)\n",
        "\n",
        "print('number of notes in the dataset:', len(cnotes_matrix))\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_vNoEXeNeya"
      },
      "source": [
        "# Generate Music\n",
        "\n",
        "Standard MIDI timings are 400/120.\n",
        "Recommended settings are: notes per slice = 30, notes timings multiplier range is 0.95 <> 1, notes durations multiplier = 1.5 in current implementation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_NcxuTHu2Ho",
        "cellView": "form"
      },
      "source": [
        "#@title Play with the settings until you get what you like \n",
        "start_note = 60 #@param {type:\"slider\", min:1, max:127, step:1}\n",
        "notes_per_slice = 30 #@param {type:\"slider\", min:8, max:60, step:1}\n",
        "number_of_slices = 30 #@param {type:\"slider\", min:0, max:400, step:1}\n",
        "relative_note_timings = True #@param {type:\"boolean\"}\n",
        "attention_span = \"augmentation\" #@param [\"8bytes_attention\", \"6bytes_attention\", \"augmentation\"]\n",
        "augmentation_strength = 4 #@param {type:\"slider\", min:0, max:8, step:1}\n",
        "output_ticks = 400 #@param {type:\"slider\", min:0, max:2000, step:100}\n",
        "ticks_per_note = 120 #@param {type:\"slider\", min:0, max:2000, step:10}\n",
        "ticks_durations_multiplier = 1 #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "notes_timings_multiplier = 0.98 #@param {type:\"slider\", min:0, max:2, step:0.01}\n",
        "notes_durations_multiplier = 1.5 #@param {type:\"slider\", min:0.1, max:5, step:0.1}\n",
        "notes_velocities_multiplier = 0.9 #@param {type:\"slider\", min:0, max:2, step:0.05}\n",
        "transpose_composition = 20 #@param {type:\"slider\", min:0, max:40, step:1}\n",
        "set_all_MIDI_patches_to_piano = False #@param {type:\"boolean\"}\n",
        "MIDI_channel_patch_00 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_01 = 24 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_02 = 32 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_03 = 40 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_04 = 42 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_05 = 46 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_06 = 56 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_07 = 71 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_08 = 73 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_09 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_10 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_11 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_12 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_13 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_14 = 0 #@param {type:\"number\"}\n",
        "MIDI_channel_patch_15 = 0 #@param {type:\"number\"} \n",
        "\n",
        "\n",
        "output_events_matrix = [['track_name', 0, b'Composition Track'], ]\n",
        "events_matrix = []\n",
        "notes_matrix = []\n",
        "index = 0\n",
        "time = 0\n",
        "x = 0\n",
        "output = []\n",
        "\n",
        "if set_all_MIDI_patches_to_piano:\n",
        "  output = [output_ticks, [['track_name', 0, b'Meddleying MAESTRO']]]\n",
        "else:\n",
        "  output = [output_ticks,\n",
        "            [['track_name', 0, b'Meddleying MAESTRO'], \n",
        "              ['patch_change', 0, 0, MIDI_channel_patch_00], \n",
        "              ['patch_change', 0, 1, MIDI_channel_patch_01],\n",
        "              ['patch_change', 0, 2, MIDI_channel_patch_02],\n",
        "              ['patch_change', 0, 3, MIDI_channel_patch_03],\n",
        "              ['patch_change', 0, 4, MIDI_channel_patch_04],\n",
        "              ['patch_change', 0, 5, MIDI_channel_patch_05],\n",
        "              ['patch_change', 0, 6, MIDI_channel_patch_06],\n",
        "              ['patch_change', 0, 7, MIDI_channel_patch_07],\n",
        "              ['patch_change', 0, 8, MIDI_channel_patch_08],\n",
        "              ['patch_change', 0, 9, MIDI_channel_patch_09],\n",
        "              ['patch_change', 0, 10, MIDI_channel_patch_10],\n",
        "              ['patch_change', 0, 11, MIDI_channel_patch_11],\n",
        "              ['patch_change', 0, 12, MIDI_channel_patch_12],\n",
        "              ['patch_change', 0, 13, MIDI_channel_patch_13],\n",
        "              ['patch_change', 0, 14, MIDI_channel_patch_14],\n",
        "              ['patch_change', 0, 15, MIDI_channel_patch_15],]]\n",
        "              \n",
        "\n",
        "if ctime > 0:\n",
        "  time = ctime\n",
        "else:\n",
        "  time = 0\n",
        "\n",
        "try:\n",
        "  if len(cev_matrix) != 0:\n",
        "    events_matrix = cev_matrix + ev_matrix\n",
        "    notes_matrix = cnotes_matrix + not_matrix\n",
        "    start_note = cnotes_matrix[-1]\n",
        "    index = notes_matrix.index(start_note, secrets.choice(range(len(notes_matrix))))\n",
        "    print('Priming_sequence: MIDI event:', cev_matrix[-1])\n",
        "  \n",
        "  else:\n",
        "    #if start_note > 0 and start_note < 128:\n",
        "    events_matrix = ev_matrix\n",
        "    notes_matrix = not_matrix\n",
        "    index = notes_matrix.index(start_note, secrets.choice(range(len(notes_matrix))))\n",
        "    print('Priming_sequence: MIDI note #', [start_note])\n",
        "\n",
        "except: \n",
        "  print('The Generator could not find the starting note in a dataset note sequence. Please adjust the parameters.')\n",
        "  print('Meanwhile, trying to generate a sequence with the MIDI note # [60]')\n",
        "  \n",
        "  try:\n",
        "    index = notes_matrix.index(60, secrets.choice(range(len(notes_matrix))))\n",
        "  except:\n",
        "    sys.exit()\n",
        "\n",
        "for i in tqdm.auto.tqdm(range(number_of_slices)):\n",
        "  for k in range(notes_per_slice):\n",
        "\n",
        "    if attention_span == '6bytes_attention':\n",
        "      if k > 2:\n",
        "        try:\n",
        "          event02 = events_matrix[index+k-3]\n",
        "          event01 = events_matrix[index+k-2]\n",
        "          event0 = events_matrix[index+k-1]\n",
        "        \n",
        "          event = events_matrix[index+k]\n",
        "\n",
        "          event1 = events_matrix[index+k+1]\n",
        "          event2 = events_matrix[index+k+2]\n",
        "          event3 = events_matrix[index+k+3]\n",
        "          index = notes_matrix.index(event1[4], secrets.choice(range(len(notes_matrix))))\n",
        "        except:\n",
        "          print('The generator had experienced an error')\n",
        "          print('Please try again, maybe even with different parameters or a larger dataset.')\n",
        "          sys.exit()\n",
        "          \n",
        "        ovent = ['note', int(time * notes_timings_multiplier), int(event[2] * notes_durations_multiplier), event[3], event[4] + 20 - transpose_composition, int(event[5] * notes_velocities_multiplier)]\n",
        "        output_events_matrix.append(ovent) \n",
        "\n",
        "        if relative_note_timings:\n",
        "          if abs(event1[1]-event[1]) > 0:\n",
        "            #time += int(min(event02[2], event01[2], event0[2], event[2], event1[2], event2[2], event3[2]) * notes_timings_multiplier)\n",
        "            time += int(event[2])\n",
        "        else:\n",
        "          if abs(event1[1]-event[1]) > 0:\n",
        "            time += int(ticks_per_note * ticks_durations_multiplier)\n",
        "      \n",
        "        x += 1\n",
        "\n",
        "    if attention_span == '8bytes_attention' or 'augmentation':\n",
        "\n",
        "      if k > 3:\n",
        "        try:\n",
        "          event03 = events_matrix[index+k-4]\n",
        "          event02 = events_matrix[index+k-3]\n",
        "          event01 = events_matrix[index+k-2]\n",
        "          event0 = events_matrix[index+k-1]\n",
        "        \n",
        "          event = events_matrix[index+k]\n",
        "\n",
        "          event1 = events_matrix[index+k+1]\n",
        "          event2 = events_matrix[index+k+2]\n",
        "          event3 = events_matrix[index+k+3]\n",
        "          event4 = events_matrix[index+k+4]\n",
        "        except:\n",
        "          print('The generator had experienced an error')\n",
        "          print('Please try again, maybe even with different parameters or a larger dataset.')\n",
        "          sys.exit()\n",
        "          \n",
        "        ovent = ['note', int(time * notes_timings_multiplier), int(event[2] * notes_durations_multiplier), event[3], event[4] + 20 - transpose_composition, int(event[5] * notes_velocities_multiplier)]        \n",
        "        output_events_matrix.append(ovent) \n",
        "\n",
        "        if relative_note_timings:\n",
        "          if abs(event1[1]-event[1]) > 0:\n",
        "            #time += int(min(event02[2], event01[2], event0[2], event[2], event1[2], event2[2], event3[2]) * notes_timings_multiplier)\n",
        "            time += int(min(event[2], event0[2], event1[2]))\n",
        "        else:\n",
        "          if abs(event1[1]-event[1]) > 0:\n",
        "            time += int(ticks_per_note * ticks_durations_multiplier)\n",
        "      \n",
        "        x += 1\n",
        "\n",
        "  if attention_span == '8bytes_attention':\n",
        "    try:\n",
        "      index = notes_matrix.index(event2[4], secrets.choice(range(len(notes_matrix))))\n",
        "\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "    \n",
        "  if attention_span == '6bytes_attention':\n",
        "    try:\n",
        "      index = notes_matrix.index(event1[4], secrets.choice(range(len(notes_matrix))))\n",
        "\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "\n",
        "  if attention_span == 'augmentation':\n",
        "    try:\n",
        "      for i in range(len(notes_matrix)-augmentation_strength):\n",
        "        if notes_matrix[i] == event03[4]:\n",
        "          if notes_matrix[i+1] == event02[4]:\n",
        "            if notes_matrix[i+2] == event01[4]:\n",
        "              if notes_matrix[i+3] == event0[4]:\n",
        "                if notes_matrix[i+4] == event[4]:\n",
        "                  if notes_matrix[i+5] == event1[4]:\n",
        "                    if notes_matrix[i+6] == event2[4]:\n",
        "                      if notes_matrix[i+7] == event3[4]:\n",
        "                        if notes_matrix[i+8] == event4[4]:\n",
        "                          index = i + augmentation_strength\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "\n",
        "  if attention_span == '8bytes_attention':\n",
        "    try:\n",
        "      for i in range(len(notes_matrix)-8):\n",
        "        if notes_matrix[i] == event03[4]:\n",
        "          if notes_matrix[i+1] == event02[4]:\n",
        "            if notes_matrix[i+2] == event01[4]:\n",
        "              if notes_matrix[i+3] == event0[4]:\n",
        "                if notes_matrix[i+4] == event[4]:\n",
        "                  if notes_matrix[i+5] == event1[4]:\n",
        "                    if notes_matrix[i+6] == event2[4]:\n",
        "                      if notes_matrix[i+7] == event3[4]:\n",
        "                        if notes_matrix[i+8] == event4[4]:\n",
        "                          index = i + 8\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "\n",
        "  if attention_span == '6bytes_attention':\n",
        "    try:\n",
        "      for i in range(len(notes_matrix)-6):\n",
        "        if notes_matrix[i] == event02[4]:\n",
        "          if notes_matrix[i+1] == event01[4]:\n",
        "            if notes_matrix[i+2] == event0[4]:\n",
        "              if notes_matrix[i+3] == event[4]:\n",
        "                if notes_matrix[i+4] == event1[4]:\n",
        "                  if notes_matrix[i+5] == event2[4]:\n",
        "                    if notes_matrix[i+6] == event3[4]:\n",
        "                        index = i+6\n",
        "    except:\n",
        "      print('Cound not find enough tokens to generate. Please try again!')\n",
        "      sys.exit()\n",
        "\n",
        "if cev_matrix == []:\n",
        "  #output += [[['track_name', 0, b'Algorithmic Music Composer']],]\n",
        "  output.append(output_events_matrix)\n",
        "  \n",
        "else:\n",
        "  #output += [[['track_name', 0, b'Algorithmic Music Composer']],]\n",
        "  output.append(cev_matrix)\n",
        "  output.append(output_events_matrix)\n",
        "\n",
        "midi_data = MIDI.opus2midi(MIDI.score2opus(output))\n",
        "\n",
        "with open('output.mid', 'wb') as midi_file:\n",
        "    midi_file.write(midi_data)\n",
        "    midi_file.close()\n",
        "\n",
        "print('First Note:', output[2][1], '=== Last Note:', output[2][-1])\n",
        "print('MIDI Stats:', MIDI.score2stats(output))\n",
        "print('Total notes:', x, 'out of expected:', len(output[2]) - 1 - len(cnotes_matrix))\n",
        "\n",
        "cev_matrix = []\n",
        "cnotes_matrix = []\n",
        "ctime = 0\n",
        "\n",
        "print('Done!')\n",
        "print('Downloading your MIDI now :)')\n",
        "from google.colab import files\n",
        "files.download('/content/output.mid')\n",
        "print('Enjoy! :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbK4CaUQOjvW"
      },
      "source": [
        "# Fun MIR stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJIcrVY6o9Gu",
        "cellView": "form"
      },
      "source": [
        "#@title A simple analysis of the output MIDI file\n",
        "MIDI_DIR = \"/content/output.mid\"\n",
        "### https://github.com/brennan2602/FYP\n",
        "\n",
        "#This file reads in the midi files in a directory, converts them to a string representation\n",
        "#when in a string representation it then gathers some statistics about the structure of the song\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def get_piano_roll(midifile):\n",
        "\tmidi_pretty_format = pretty_midi.PrettyMIDI(midifile)\n",
        "\tpiano_midi = midi_pretty_format.instruments[0] # Get the piano channels\n",
        "\tpiano_roll = piano_midi.get_piano_roll(fs=20)\n",
        "\treturn piano_roll\n",
        "\n",
        "#uses split encoding scheme (here only encoding the note values)\n",
        "#works by looping through time increments of the piano roll array and writing the notes being played\n",
        "#at a given time sample as a number on the corresponding line of a string # is written when no notes played for that\n",
        "#sample\n",
        "def encode(arr):\n",
        "    timeinc=0\n",
        "    outString=\"\"\n",
        "    for time in arr:\n",
        "        notesinc = -1\n",
        "        #print(time)\n",
        "        if np.all(time==0):\n",
        "            outString=outString+\"#\"\n",
        "        for vel in arr[timeinc]:\n",
        "            notesinc=notesinc+1\n",
        "            if vel != 0:\n",
        "                noteRep=str(notesinc) + \" \"\n",
        "                #print(noteRep)\n",
        "                outString=outString+noteRep\n",
        "        outString=outString+\"\\n\"\n",
        "        timeinc = timeinc+1\n",
        "    return outString\n",
        "\n",
        "\n",
        "def getSilences(test):\n",
        "    test=test[:-1] #removing last line in string (always blank)\n",
        "    output=test.split(\"\\n\") #splitting into array\n",
        "    res = len(output)\n",
        "    #initialising counters\n",
        "    maxcounter=0\n",
        "    counter=0\n",
        "    silenceCount=0\n",
        "\n",
        "    for x in output:\n",
        "        if x == \"#\": #when a \"#\" is seen nothing is being played that sample\n",
        "            counter=counter+1 #this tracks a streak of silences\n",
        "            silenceCount+=1 #this tracks total silences\n",
        "        if x != \"#\":\n",
        "            counter=0 #reseting streak\n",
        "        if counter>maxcounter:\n",
        "            maxcounter=counter #updating longest silence streak when appropriate\n",
        "    return maxcounter,silenceCount\n",
        "\n",
        "\n",
        "#by looking at the length of song and the amount of silences this returns % silence\n",
        "def getPercentSilence(gen,silences):\n",
        "    test = gen\n",
        "    test = test[:-1]\n",
        "    output = test.split(\"\\n\")\n",
        "    res = len(output)\n",
        "    percent=silences/res\n",
        "    return percent\n",
        "\n",
        "\n",
        "def getStatsNotes(test):\n",
        "    test=test[:-1] #get rid of blank line at the end\n",
        "    notes=[]\n",
        "    output = test.split(\"\\n\") #split string on new lines\n",
        "\n",
        "    #initial values updated while looping through\n",
        "    maxPerSamp=0\n",
        "    silenceSamp=0\n",
        "    notesPlayed=0\n",
        "    maxNotes=0\n",
        "    maxVal=0\n",
        "    minVal=127\n",
        "\n",
        "    for x in output:\n",
        "        samp=x.split(\" \")\n",
        "        samp=samp[:-1] #theres a blank result at the end of array from split this indexing removes it\n",
        "        while \"0\" in samp:\n",
        "            samp.remove(\"0\") #sometimes 0 samples exist this removes them as they aren't notes played\n",
        "        if len(samp)==0:\n",
        "            silenceSamp+=1 #counting silences\n",
        "        notesPlayed=notesPlayed+len(samp) #counting notes played\n",
        "        if len(samp)>0:\n",
        "            #getting max and min note values at this time step\n",
        "            minimum=min(samp)\n",
        "            maximum=max(samp)\n",
        "            #updating max and min values note values for song if appropriate\n",
        "            if int(minimum)<minVal:\n",
        "                minVal=int(minimum)\n",
        "            if int(maximum)>maxVal:\n",
        "                maxVal=int(maximum)\n",
        "        #updating maximum number of notes per sample if appropriate\n",
        "        if len(samp)>maxNotes:\n",
        "            maxNotes=len(samp)\n",
        "    rangeNotes=maxVal-minVal #spread of notes\n",
        "    avgNotes = notesPlayed / len(output) #average notes per sample\n",
        "    adjNotes=notesPlayed /(len(output)-silenceSamp) #average notes per sample adjusted to remove silent samples\n",
        "    return rangeNotes, maxVal, minVal,maxNotes,avgNotes,adjNotes\n",
        "\n",
        "\n",
        "files=glob.glob(MIDI_DIR)#point towards directory with midi files (here same folder)\n",
        "print(files)\n",
        "\n",
        "for f in files:\n",
        "    print(f)\n",
        "    pr = get_piano_roll(f) #gets piano roll representation of the midi file\n",
        "    arr = pr.T\n",
        "    outString= encode(arr) #gets a string representation of the midi file\n",
        "    maxsilences, silences = getSilences(outString) #by passing in the encoded string get longest silence and the total\n",
        "                                                   #number of samples which are silent\n",
        "    noteRange, maxVal, minVal, maxNotes, avgNotes, adjAvg =getStatsNotes(outString) # getting some stats by looping\n",
        "                                                                                    # through encoded data\n",
        "    percentSilence= getPercentSilence(outString,silences) # get % silence from silence / outString length\n",
        "\n",
        "    #printing out to the user\n",
        "    print(\"longest silence is \",maxsilences,\"samples long\")\n",
        "    print(\"silence covers:\",round(percentSilence,4),\"%\")\n",
        "    print(\"notes span range:\",noteRange)\n",
        "    print(\"max note value:\",maxVal)\n",
        "    print(\"min note value:\",minVal)\n",
        "    print(\"average number of notes per sample:\",round(avgNotes,4))\n",
        "    print(\"average number of notes per sample (adjusted to remove silence samples):\",round(adjAvg,4))\n",
        "    print(\"max number of notes played in a sample:\",maxNotes)\n",
        "    print(\"\\n\")\n",
        "\n",
        "#NOTE some minor discrepencies vs reading in from generated file directly\n",
        "#However this does provide a uniform check to use for songs generated by both encoding schemes\n",
        "#Can also be used to evaluate training file\n",
        "#uses split encoding to get the text representation for ease of development"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Snu3fb4N-Nd"
      },
      "source": [
        "# Congrats! :) You did it :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxsedAQbS_wR",
        "cellView": "form"
      },
      "source": [
        "#@title Make a nice Arc diagram of the output to show friends and family :)\n",
        "MIDI_file_track_to_visualize = 1 #@param {type:\"number\"}\n",
        "multi_track_input = True\n",
        "\n",
        "midi_file = '/content/output.mid'\n",
        "plot_title = \"Meddleying MAESTRO Output Arc Diagram\"\n",
        "\n",
        "def maximal_matching_pair( s, substring_length, old_index=-1 ):\n",
        "    '''\n",
        "    find the first pair of matching substrings at least as long as the specified length\n",
        "    '''\n",
        "    if substring_length > len(s)/2:\n",
        "        return (len(substring_length), -1) # fail- futile to keep searching with this string\n",
        "\n",
        "    head = s[:substring_length]\n",
        "    tail = s[substring_length:]\n",
        "    index = tail.find(head) \n",
        "    if index == -1:\n",
        "        if substring_length > 2:\n",
        "            return (substring_length-1, old_index) # success\n",
        "        return (substring_length, index) # fail- failed on first 2 character substring attempt \n",
        "    \n",
        "    return maximal_matching_pair(s, substring_length+1, index) # keep looking\n",
        "\n",
        "def first_matching_substring_pair( s, start=0 ):\n",
        "    '''\n",
        "    returns the first matching substring pair of at least length 2 in the given string, \n",
        "    ignoring all characters of the string before the given start index \n",
        "    '''\n",
        "    if start < 0:\n",
        "        return () # invalid input: start must be non-negative\n",
        "\n",
        "    if len(s[start:]) < 4:\n",
        "        return () # fail: string too short to find matching substrings of minimal length 2\n",
        "\n",
        "    minimal_substring_length = 2\n",
        "    (length, distance) = maximal_matching_pair(s[start:], minimal_substring_length)\n",
        "    if distance != -1:\n",
        "        return (start, length, distance) # success\n",
        "    \n",
        "    return first_matching_substring_pair(s, start+1) # keep looking\n",
        "\n",
        "def matching_substring_pairs( string ):\n",
        "    '''\n",
        "    returns a collection of consecutive substring pairs encoded as (start, length, distance) where\n",
        "    * start is the index of the first character of the first substring of the matching substring pair,\n",
        "    * length is the length of the substrings in the matching substring pair, and\n",
        "    * distance is the distance from the end of the first substring to the begining of the second substring\n",
        "    '''\n",
        "    pairs = []\n",
        "    pair = first_matching_substring_pair(string, 0)\n",
        "    while pair:\n",
        "        pairs.append(pair)\n",
        "        (start, length, distance) = pair\n",
        "        pair = first_matching_substring_pair(string, start+length)\n",
        "    return pairs\n",
        "\n",
        "def plot_arc_diagram( string, plot_title=\"\" ):\n",
        "    slds = matching_substring_pairs(string)\n",
        "    bews = map( lambda sld: (sld[0], sum(sld)+sld[1], sld[1]), slds )\n",
        "    plot_arc_diagram_impl(bews, plot_title)\n",
        "\n",
        "#  begin                                        end                 \n",
        "# /                                            /\n",
        "# ***********-----------O-----------***********\n",
        "# |--width--|            \\          |--width--|\n",
        "#           |-inner rad-| \\\n",
        "# |-----outer radius----|  center\n",
        "\n",
        "def plot_ring( ax, begin, end, width ):\n",
        "    cx = 0.5*(begin + end)\n",
        "    center = (cx, 0)\n",
        "    outer_radius = cx - begin\n",
        "    inner_radius = outer_radius - width\n",
        "\n",
        "    mypie, _ = ax.pie([1], radius=outer_radius, colors=[(0.4,0.4, 1.0, 0.3)], center=center )\n",
        "    plt.setp( mypie, width=width)\n",
        "\n",
        "    return outer_radius\n",
        "\n",
        "def plot_arc_diagram_impl( bews, plot_title ):\n",
        "    fig, ax = plt.subplots(subplot_kw={'aspect': 'auto'})\n",
        "\n",
        "    x_min = 0\n",
        "    x_max = 1920\n",
        "    max_width = 1080\n",
        "    for bew in bews:\n",
        "        x_max = max(x_max, bew[1])\n",
        "        orad = plot_ring(ax, bew[0], bew[1], bew[2])\n",
        "        max_width = max(max_width, orad)\n",
        "\n",
        "    ax.set_xlim(x_min, x_max)\n",
        "    ax.set_ylim( -max_width, max_width)\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    title_obj = plt.title(plot_title, loc='center')\n",
        "    plt.setp(title_obj, color=(0.0, 0.0, 0.0, 1)) \n",
        "\n",
        "    plt.savefig('output.png', dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def stringify_notes(midi_file, track_number):\n",
        "\n",
        "    mid = MidiFile(midi_file)\n",
        "    track_notes = {}\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        track_notes[i] = ''\n",
        "        for msg in track:\n",
        "            if( msg.type == 'note_on'):\n",
        "                track_notes[i] += str(msg.note) +'n'\n",
        "            if( msg.type == 'note_off'):\n",
        "                track_notes[i] += str(msg.note) +'f'\n",
        "    return track_notes[track_number]\n",
        "\n",
        "if multi_track_input:\n",
        "  try:\n",
        "    plot_arc_diagram(stringify_notes(midi_file, MIDI_file_track_to_visualize), plot_title)\n",
        "    if debug: \n",
        "      print('Debug mode')\n",
        "    print('MIDI Track #', MIDI_file_track_to_visualize, 'Arc Diagram')\n",
        "    Image('output.png')\n",
        "  except:\n",
        "    print('Error in processing your MIDI file. Sorry.')\n",
        "    sys.exit\n",
        "from google.colab import files\n",
        "files.download('/content/output.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA6K04h9OpK8"
      },
      "source": [
        "# MIDI Patch Numbers Reference Chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fRNHIhVkI85"
      },
      "source": [
        "***\n",
        "\n",
        "## General MIDI Level 1 Instrument Families\n",
        "\n",
        "### The General MIDI Level 1 instrument sounds are grouped by families. In each family are 8 specific instruments.\n",
        "\n",
        "https://www.midi.org/specifications-old/item/gm-level-1-sound-set\n",
        "\n",
        "***\n",
        "\n",
        "## PC #\tFamily Name\n",
        "\n",
        "1-8\tPiano\n",
        "\n",
        "9-16\tChromatic Percussion\n",
        "\n",
        "17-24\tOrgan\n",
        "\n",
        "25-32\tGuitar\n",
        "\n",
        "33-40\tBass\n",
        "\n",
        "41-48\tStrings\n",
        "\n",
        "49-56\tEnsemble\n",
        "\n",
        "57-64\tBrass\n",
        "\n",
        "65-72\tReed\n",
        "\n",
        "73-80\tPipe\n",
        "\n",
        "81-88\tSynth Lead\n",
        "\n",
        "89-96\tSynth Pad\n",
        "\n",
        "97-104\tSynth Effects\n",
        "\n",
        "105-112\tEthnic\n",
        "\n",
        "113-120\tPercussive\n",
        "\n",
        "121-128\tSound Effects\n",
        "\n",
        "***\n",
        "\n",
        "Note: While GM1 does not define the actual characteristics of any sounds, the names in parentheses after each of the synth leads, pads, and sound effects are, in particular, intended only as guides).\n",
        "\n",
        "***\n",
        "\n",
        "### PC #\tInstrument Name \n",
        "#### Subtract 1 from MIDI patch index number below to get MIDI patch number to use\n",
        "1.\tAcoustic Grand Piano\n",
        "2.\tBright Acoustic Piano\n",
        "3.\tElectric Grand Piano\n",
        "4.\tHonky-tonk Piano\n",
        "5.\tElectric Piano 1\n",
        "6.\tElectric Piano 2\n",
        "7.\tHarpsichord\n",
        "8.\tClavi\n",
        "9.\tCelesta\n",
        "10.\tGlockenspiel\n",
        "11.\tMusic Box\n",
        "12.\tVibraphone\n",
        "13.\tMarimba\n",
        "14.\tXylophone\n",
        "15.\tTubular Bells\n",
        "16.\tDulcimer\n",
        "17.\tDrawbar Organ\n",
        "18.\tPercussive Organ\n",
        "19.\tRock Organ\n",
        "20.\tChurch Organ\n",
        "21.\tReed Organ\n",
        "22.\tAccordion\n",
        "23.\tHarmonica\n",
        "24.\tTango Accordion\n",
        "25.\tAcoustic Guitar (nylon)\n",
        "26.\tAcoustic Guitar (steel)\n",
        "27.\tElectric Guitar (jazz)\n",
        "28.\tElectric Guitar (clean)\n",
        "29.\tElectric Guitar (muted)\n",
        "30.\tOverdriven Guitar\n",
        "31.\tDistortion Guitar\n",
        "32.\tGuitar harmonics\n",
        "33.\tAcoustic Bass\n",
        "34.\tElectric Bass (finger)\n",
        "35.\tElectric Bass (pick)\n",
        "36.\tFretless Bass\n",
        "37.\tSlap Bass 1\n",
        "38.\tSlap Bass 2\n",
        "39.\tSynth Bass 1\n",
        "40.\tSynth Bass 2\n",
        "41.\tViolin\n",
        "42.\tViola\n",
        "43.\tCello\n",
        "44.\tContrabass\n",
        "45.\tTremolo Strings\n",
        "46.\tPizzicato Strings\n",
        "47.\tOrchestral Harp\n",
        "48.\tTimpani\n",
        "49.\tString Ensemble 1\n",
        "50.\tString Ensemble 2\n",
        "51.\tSynthStrings 1\n",
        "52.\tSynthStrings 2\n",
        "53.\tChoir Aahs\n",
        "54.\tVoice Oohs\n",
        "55.\tSynth Voice\n",
        "56.\tOrchestra Hit\n",
        "57.\tTrumpet\n",
        "58.\tTrombone\n",
        "59.\tTuba\n",
        "60.\tMuted Trumpet\n",
        "61.\tFrench Horn\n",
        "62.\tBrass Section\n",
        "63.\tSynthBrass 1\n",
        "64.\tSynthBrass 2\n",
        "65.\tSoprano Sax\n",
        "66.\tAlto Sax\n",
        "67.\tTenor Sax\n",
        "68.\tBaritone Sax\n",
        "69.\tOboe\n",
        "70.\tEnglish Horn\n",
        "71.\tBassoon\n",
        "72.\tClarinet\n",
        "73.\tPiccolo\n",
        "74.\tFlute\n",
        "75.\tRecorder\n",
        "76.\tPan Flute\n",
        "77.\tBlown Bottle\n",
        "78.\tShakuhachi\n",
        "79.\tWhistle\n",
        "80.\tOcarina\n",
        "81.\tLead 1 (square)\n",
        "82.\tLead 2 (sawtooth)\n",
        "83.\tLead 3 (calliope)\n",
        "84.\tLead 4 (chiff)\n",
        "85.\tLead 5 (charang)\n",
        "86.\tLead 6 (voice)\n",
        "87.\tLead 7 (fifths)\n",
        "88.\tLead 8 (bass + lead)\n",
        "89.\tPad 1 (new age)\n",
        "90.\tPad 2 (warm)\n",
        "91.\tPad 3 (polysynth)\n",
        "92.\tPad 4 (choir)\n",
        "93.\tPad 5 (bowed)\n",
        "94.\tPad 6 (metallic)\n",
        "95.\tPad 7 (halo)\n",
        "96.\tPad 8 (sweep)\n",
        "97.\tFX 1 (rain)\n",
        "98.\tFX 2 (soundtrack)\n",
        "99.\tFX 3 (crystal)\n",
        "100.\tFX 4 (atmosphere)\n",
        "101.\tFX 5 (brightness)\n",
        "102.\tFX 6 (goblins)\n",
        "103.\tFX 7 (echoes)\n",
        "104.\tFX 8 (sci-fi)\n",
        "105.\tSitar\n",
        "106.\tBanjo\n",
        "107.\tShamisen\n",
        "108.\tKoto\n",
        "109.\tKalimba\n",
        "110.\tBag pipe\n",
        "111.\tFiddle\n",
        "112.\tShanai\n",
        "113.\tTinkle Bell\n",
        "114.\tAgogo\n",
        "115.\tSteel Drums\n",
        "116.\tWoodblock\n",
        "117.\tTaiko Drum\n",
        "118.\tMelodic Tom\n",
        "119.\tSynth Drum\n",
        "120.\tReverse Cymbal\n",
        "121.\tGuitar Fret Noise\n",
        "122.\tBreath Noise\n",
        "123.\tSeashore\n",
        "124.\tBird Tweet\n",
        "125.\tTelephone Ring\n",
        "126.\tHelicopter\n",
        "127.\tApplause\n",
        "128.\tGunshot\n",
        "\n",
        "\n"
      ]
    }
  ]
}